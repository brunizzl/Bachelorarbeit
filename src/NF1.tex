



\chapter {Normalform} \label{secErsteNormalform}

Das Kernthema dieser Arbeit ist die Vereinfachung von Termen. Eine Vereinfachung ist allerdings nur gültig, sofern sich die Bedeutung des vereinfachten Terms gegenüber der des ursprünglichen Terms nicht geändert hat. Da ein Term in sich keine Bedeutung trägt, muss eine Vereinfachung immer in Bezug auf eine Interpretation $\Const{eval}(u, v)$ gesehen werden. Etwa kann der Ausdruck $X A X^{-1}$ zu $A$ vereinfacht werden, wenn $X, A \in \mathbb{C} \setminus \{0\}$, allerdings ist die Vereinfachung allgemein nicht möglich, sollten die Symbole $X$ und $A$ für Matritzen stehen. \\
Im Folgenden wird von der Assoziativität oder Kommutativität bestimmter Funktionssymbole gesprochen. Diese ist immer im Kontext der Interpretation $\Const{eval}(u, v)$ zu sehen. Gleichzeitig ist aber auch klar, dass unabhängig von der Interpretation verschiedene Funktionssymbole die Rolle der Multiplikation übernehmen müssen, sollte sowohl skalare Multiplikation als auch Matrixmultiplikation im selben Term möglich sein. $X A X^{-1}$ als Matrixmultiplikation könnte der Term $(\texttt{prod'}, X, A, (\texttt{pow}, X, -1))$ darstellen. Sind $A$ und $X$ Skalare, wäre der Ausdruck als $(\texttt{prod}, X, A, (\texttt{pow}, X, -1))$ schreibbar. Das Funktionssymbol $\texttt{prod'}$ steht dann für ein nicht-kommutatives Produkt, während die Reihenfolge der Parameter in einer Funktionsanwendung von $\texttt{prod}$ keine Rolle spielt.\\

In diesem Abschnitt werden einfache Termumformungen beschrieben, die isolierte Eingenschaften einzelner Funktionen ausnutzen. Ziel ist es, Äquivalenzklassen für die Erkennung von Mustern zu schaffen, die über die Austauschbarkeit jeder Mustervariable mit einem beliebigen Literal hinausgehen. Als Beispiel dient die Regel der Faktorisierung, normal geschrieben $x \cdot y + x \cdot z = x \cdot (y + z)$. In der in Unterkapitel \ref{subsecMuster} etablierten Musterschreibweise, mit Mustervariablen \textbf{fett} geschrieben, wird daraus:
$$(\texttt{sum}, (\texttt{prod}, \mathbf x, \mathbf y), (\texttt{prod}, \mathbf x, \mathbf z)) \mapsto (\texttt{prod}, \mathbf x, (\texttt{sum}, \mathbf y, \mathbf z))$$
Ziel ist, die Regel auf das Literal $(\texttt{sum}, (\texttt{prod}, a, b), (\texttt{prod}, a, c, d))$ anwendbar zu machen bzw. eine Regel schreiben zu können, die eine ähnliche Struktur hat und diesen Fall mit abdeckt. 
Würde das Literal geschrieben sein als $$(\texttt{sum}, (\texttt{prod}, a, b), (\texttt{prod}, a, (\texttt{prod}, c, d))),$$ gäbe es ein Match $v_p$ der linken Regelseite mit dem Literal, mit $v_p~\mathbf x = a$, $v_p~\mathbf y = b$ und $v_p~\mathbf z = (\texttt{prod}, c, d)$. Ergebnis dieses Kapitels wird eine in Abschnitt \ref{subsecMuster} genutzte Projektion ${\Const{normalize} \colon T \rightarrow T}$ sein, welche die Beispielregel auf das Beispielliteral in seiner ursprünglichen Form anwendbar macht.\\

Weiteres Ziel dieses Kapitels ist, dass möglichst viele Literale mit identischer Auswertung identische normalisierter Terme besitzen. So soll etwa die Normalisierung von $t_1 = (\texttt{sum}, a, b, c)$ identisch zur Normalisierung von $t_2 = (\texttt{sum}, b, a, c)$ identisch zur Normalisierung von $t_3 = (\texttt{sum}, (\texttt{sum}, b, a), c)$ sein. Je mehr Literale identischen Wertes auch zu identischen Termen normalisiert werden, desto besser können Muster erkannt werden, in denen dieselbe Mustervariable mehrfach vorkommt. Interessant ist dabei, dass derselbe Effekt auch erreicht werden würde, wenn man eine Menge von Ersetzungsregeln um entsprechende normalisierende Ersetzungsregeln ergänzt. Wo die Grenze in der Arbeitsteilung von einer fest implementierten $\Const{normalize}$ Funktion zu den Regeln in einem Termersetzungssystem liegt, ist prinzipiell fast beliebig und in erster Linie eine Frage des Aufwandes, sowohl in Programmierung als auch Laufzeit. Etwa würde eine Darstellung natürlicher Zahlen ähnlich der Church-Numerale, wie sie in der Fachliteratur, etwa bei Baader und Nipkow \cite{baader_nipkow_1998}, üblich ist, erlauben, Rechenoperationen auf den natürlichen Zahlen komplett mit einer endlichen Menge von Mustern auszuwerten. Nachteile dieser Vorgehensweise wären allerdings eine langsamere Auswertung, mehr Speicherbedarf und nur sehr schwierig zu lesende Ergebnisse. Andersherum wäre etwa die Anwendung der ersten binomischen Formel prinzipiell auch in der $\Const{normalize}$ Funktion möglich, allerdings steht der Aufwand, manuell auf das Muster zu testen, nur möglicherweise minimalen Geschwindigkeitsvorteilen des Gesamtsystems gegenüber. Die Transformationen, die in diesem Kapitel der $\Const{normalize}$ Funktion zugewiesen werden, sollen also idealerweise nicht einfacher mit Mustern implementierbar sein.\\

In diesem Kapitel werden häufig Abschnitte der Parameter einer Funktionsanwendung beliebiger Länge der Form $\elems t i k$ vorkommen. Kompakt wird $ts...$ für den (möglicher\-weise leeren) Abschnitt des Funktionsanwendungstupels geschrieben. Das $s$ in $ts...$ ist dann nicht als einzelnes Symbol zu lesen, sondern als Suffix um $t$ in den Plural zu setzen. \\$(f, \elems t 1 k, a, \elems t {k+2} n)$ kann also äquivalent $(f, ts..., a, rs...)$ geschrieben werden, mit $(\elems t 1 k) = (ts...)$ und $(\elems t {k+2} n) = (rs...)$.\\

\section {Assoziative Funktionsanwendungen}
Die geschachtelte Anwendung einer assoziativen Funktion führt je nach Klammersetzung zu verschiedenen mathematisch equivalenten Termen. Als Beispiel dient hier die Addition, dargestellt als Anwendung des Funktionssymbols $\texttt{sum}$. Die folgenden Ausdrücke sind paarweise verschiedene Terme, jedoch in ihrer Interpretation als Summe von $a$, $b$, $c$ und $d$ alle mathematisch äquivalent.
\begin{equation*}
	\begin{split}
	   (\texttt{sum}, (\texttt{sum}, (\texttt{sum}, a, b), c), d) 
    &= (\texttt{sum}, (\texttt{sum}, a, (\texttt{sum}, b, c)), d)\\
	&= (\texttt{sum}, (\texttt{sum}, a, b), (\texttt{sum}, c, d))\\
	&= (\texttt{sum}, a, (\texttt{sum}, b, (\texttt{sum}, c, d)))\\
	&= \dots \\
	\end{split}
\end{equation*}
Es gibt mehrere Optionen eine solche Schachtelung in einem Term zu normalisieren, also in eine eindeutige Form zu bringen. Die erste ist, festzulegen, dass in der normalisierten Form höchstens eins der beiden Argumente einer binären assoziativen Funktion wieder Anwendung des selben Funktionssymbols sein darf. Wählt man das zweite Argument dafür aus, wird die Summe in der Normalform dargestellt als $(\texttt{sum}, a, (\texttt{sum}, b, (\texttt{sum}, c, d)))$. Ein Problem der Methode ist, dass nicht immer alle Argumente eines assoziativen Funktionssymbols direkt vorliegen.\\
Alternativ kann man die Summe von zwei Argumenten auch als Spezialfall einer Summe von $n \in \mathbb{N}$ Argumenten auffassen, gewohnt geschrieben als $\Sigma_{x \in \{a, b, c, d\}} x$. Dieser Weg wird im Folgenden gewählt, wobei die Darstellung als Term dann $(\texttt{sum}, a, b, c, d)$ ist. Assoziative Funktionen sind in der gewählten Darstellung damit variadisch. Eker (\cite{BipartiteGraphMatching}), Benanav (\cite{NPHardMatching}) und Kounalis (\cite{ACPatternCompiler}) wählen unter anderen ebenfalls diese Darstellung. 
Die Normalisierung von Funktionsanwendungen des assoziativen Funktionssymbols $f$ bedeutet dann, geschachtelte Funktionsanwendungen in eine einzelne Funktionsanwendung zu übersetzen. 
$$(f, as..., f(bs...), cs...) \mapsto (f, as..., bs..., cs...)$$
Der Spezialfall ist eine assoziative Funktionsanwendung mit nur einem Parameter. Diese kann immer zu dem Parameter selbst normalisiert werden. 

Als Algorithmus dargestellt sind die Überlegungen in Algorithmus \ref{flatten}.
Die Funktion $\tilde u$ kann hier und in den weiteren Algorithmen dieses Kapitels als \glqq{natürliche}\grqq{} Interpretation der Menge von Funktionssymbolen gesehen werden, ähnlich $u$ in Beispiel \ref{bEval}. Prinzipiell ist für die Gültigkeit des Kapitel aber egal, in welchem Kontext die Abbildungsvorschrift von $\tilde u$ Sinn ergibt oder ob ein solcher Kontext überhaupt existiert. Wichtig ist nur, dass $\tilde u$ über das gesamte Kapitel hinweg eine einheitliche Abbildungsvorschrift hat.

\begin{algorithm}
\DontPrintSemicolon
\caption{$\Const{flatten} \colon T \rightarrow T$}\label{flatten}
\KwIn{$t \in T(F, C)$}

\If{$t = (f, t_1)$ mit $\tilde u~f$ assoziativ}{
    \Return {$t_1$}
}
\ElseIf{$t = (f, \elems t 0 {n-1})$ mit $\tilde u~f$ assoziativ}{
    \While{$t = (f, xs..., (f, ys...), zs...)$}{
        $t \leftarrow (f, xs..., ys..., zs...)$\;
    }
}
\Return {$t$}
\end{algorithm}

\section{Kommutative Funktionsanwendungen} \label{subsecNormalSortieren}
Eine Normalform für kommutative Funktionsanwendungen erfordert eine totale Ordnung auf der Menge aller Terme $T(F, C)$. 

\begin{definition}~\\ \label{defOrdnungKleiner}
Aufbauend auf einer totalen Ordnung von $F$ sowie $C$, kann eine lexikographische Ordnung $<$ von $T$ frei nach \cite{LexikografischeOrdnung} wie folgt definiert werden: 
\begin{enumerate}
	\item{sind $c, \tilde{c} \in T$ Konstantensymbole, so ist die Ordnung identisch zu der Ordnung in $C$}
	\item{sind $c, a, \in T$ sowie $c$ ein Konstantensymbol und $a$ eine Funktionsanwendung, gilt $c < a$ }
	\item{sind $a = (f, ts...), b = (g, rs...) \in T$ Funktionsanwendungen und ist $f < g$, gilt $a < b$}
	\item{sind $a = (f, t_1, \dots, t_n), b = (f, r_1, \dots, r_m) \in T$ Funktionsanwendungen, ist die Ordnung wie folgt}
	\begin{enumerate}
		\item{wenn $\exists k \leq \min{(n, m)} \colon \forall i < k ~ t_i = r_i ,~ t_k \neq r_k $, gilt ${a < b \iff t_k < r_k}$}
		\item{ist $n < m$ und $\forall i < n\colon t_i = r_i$, gilt $a < b$}
		\item{ist $n = m$ und $\forall i \leq n\colon t_i = r_i$, gilt $a = b$}
	\end{enumerate}
\end{enumerate}

\end{definition}

\begin{lemma} \label{lemMinMax}
$T$ hat genau dann ein Minimum, wenn $C$ ein Minimum hat $(1)$. $T$ hat kein endlich großes Maximum $(2)$.
\end{lemma}

\textbf{Beweis}.\\
Teil $(1)$ folgt daraus, dass die Konstantensymbole selbst bereits Terme sind und kleiner als jede Funktionsanwendung sind. Ein Minimum von $C$ ist damit gleichzeitig Minimum von $T$.

Teil $(2)$ folgt aus einem Widerspruch. Angenommen es gäbe einen größten endlichen Term $t$. Der Term $t'$ ist identisch zu $t$, nur die Konstantensymbole von $t$ sind durch beliebige Funktionsanwendungen ersetzt. Der neue Term $t'$ ist größer als $t$.
\hfill $\square$\\

Zur Normalisierung einer kommutativen Funktionsanwendung werden zuerst alle Parameter normalisiert, dann können die Parameter nach der lexikographischen Ordnung $<$ von $T$ sortiert werden. 

\section{Teilweise Auswertung} \label{subsecNormalKombinieren}

\begin{algorithm}
\DontPrintSemicolon
\caption{$\Const{combine} \colon T \rightarrow T$}\label{combine}
\KwIn{$t \in T(F, C)$}

\If{$\Const{eval}(\tilde u, \Const{id})~t = c \in C$}{
    \Return {$c$}
}
\ElseIf{$t = (f, \elems t 0 {n-1})$ und $\tilde u~f$ assoziativ}{
    \If{$\tilde u~f$ kommutativ}{
        \While{$t = (f, us..., x, vs..., y, ws...) $ und $ \tilde u~f~(x, y) = z \in C$}{
            $t \leftarrow (f, z, us..., vs..., ws...)$\;
        }
    }
    \Else{
        \While{$t = (f, us..., x, y, vs...) $ und $ \tilde u~f~(x, y) = z \in C$}{
            $t \leftarrow (f, us..., z, vs...)$\;
        }
    }
}
\end{algorithm}

Mit der Darstellung einer assoziativen Funktion mit einem variadischen Funktionssymbol $f \in F$, kann eine Funktionsanwendung von $f$ in bestimmen Fällen teilweise ausgewertet werden. Als Beispiel kann die Summe der Symbole $1$, $3$ und $\texttt{a}$ geschrieben als $(\texttt{sum}, 1, 3, \texttt{a})$ zur Summe $(\texttt{sum}, 4, \texttt{a})$ transformiert werden. 
Gilt allgemein für ein Funktionssymbol $f \in F$, dass $\tilde u~f$ assoziativ ist, reicht es aus, zwei aufeinander folgende Argumente $x$ und $y$ in einer Funktionsanwendung von $f$ zu finden, mit denen die Funktionsanwendung $(f, x, y)$ auswertbar wäre. $x$ und $y$ können dann entsprechend ersetzt werden.
$$\Const{eval}(\tilde u, \Const{id})~(f, x, y) = z \in C \implies (f, us..., x, y, vs...) \mapsto (f, us..., z, vs...)$$

Ist $\tilde u~f$ zudem kommutativ, müssen $x$ und $y$ nicht notwendigerweise direkt aufeinander folgen:
$$\Const{eval}(\tilde u, \Const{id})~(f, x, y) = z \in C \implies (f, us..., x, vs..., y, ws...) \mapsto (f, z, us..., vs..., ws...)$$

Eine normalisierte Funktionsanwendung enthält keine zwei auf diese Art ersetzbare Argumente $x$ und $y$ mehr. Weiter ist jede Funktionsanwendung, die als ganzes zu einer Konstante $z \in C$ auswertbar ist, ausgewertet.\\
Als Algorithmus dargestellt sind die Überlegungen in Algorithmus \ref{combine}. Die Verfahren zur Normalisierung assoziativer und kommutativer Funktionssymbole werden auch von Eker \cite{BipartiteGraphMatching} beschrieben.

\section{Kombination der einzelnen Vereinfachungen} \label{subsecKomboNormal}

\begin{algorithm}
\DontPrintSemicolon
\caption{$\Const{normalize} \colon T \rightarrow T$}\label{normalize}
\KwIn{$t \in T(F, C)$}

\If {$t = (f, t_1, \dots, t_n)$}{
	\For {$i \in \{1, \dots, n\}$}{
		$t_i \leftarrow \Const{normalize}~t_i$\;
	}
}
$t \leftarrow \Const{flatten}~t$\;
$t \leftarrow \Const{combine}~t$\;
\If {$t = (f, t_1, \dots, t_n)$ mit $\tilde u~f$ kommutativ}{
	sortiere $t_1, \dots, t_n$ lexikographisch nach Ordnung $<$\;
}
\Return $t$ 
\end{algorithm}
Algorithmus \ref{normalize} kombiniert die einzelnen Überlegungen dieses Kapitels: Zuerst werden alle Argumente einer Funktionsanwendung normalisiert, dann die Funktionsanwendung selbst.





