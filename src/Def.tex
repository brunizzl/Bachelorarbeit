


\chapter{Grundlegende Definitionen} \label{secGrundlegendeDefinitionen}

\section{Term} \label{subsecTerm}
Eine Menge von Termen $T$ ist in dieser Arbeit immer  in Abhängigkeit der nicht-leeren Mengen $F$ und $C$, sowie der \emph{\Gls{Stelligkeitsfunktion}} $\Const{arity} \colon F \rightarrow \mathbb{N} \cup \{\omega\}$ definiert, ähnlich der Notation von Benanav et. al. in \cite{NPHardMatching}. $F$ enthält die sogenannten \emph{Funktionssymbole}. Beispiele für mögliche Elemente in $F$ sind \texttt{sin} und \texttt{sqrt}, zudem auch Operatoren wie die Division, etwa geschrieben als \texttt{divide}. Die Stelligkeitsfunktion $\Const{arity}$ gibt für jedes Funktionssymbol an, wie viele Argumente erwartet werden. Eine mögliche Stelligkeit der genannten Beispielsymbole ist die folgende:

$$\Const{arity}~f = \begin{cases}
2 & f  = \texttt{divide}\\
1 & f \in \{\texttt{sin}, \texttt{sqrt}\}\\
\end{cases}$$

Kann eine \Gls{Funktionssymbol} $f$ beliebig viele Argumente entgegennehmen, wird gesagt, dass $f$ \emph{variadische} Stelligkeit hat oder \emph{\gls{variadisch}} ist. Die Stelligkeitsfunktion bildet $f$ dann auf $\omega$ ab. 

Die Menge $C$ enthält die \emph{Konstantensymbole}. Mit den genannten Beispielen für Funktionssymbole ergibt etwa $C = \mathbb R$ Sinn. Wichtig ist, dass im folgenden nicht vorausgesetzt wird, dass zwangsweise jedem \Gls{Konstantensymbol} ein eindeutiger numerischer Wert zugeordnet werden kann\footnote{Die Symbole unbekannten Wertes werden häufig von den Konstantensymbolen getrennt und Variablensymbole genannt. Diese Unterscheidung wird hier nicht getroffen, primär um die Definitionen einfach zu halten.}.




\begin{definition}\label{defTerm}~\\
Ein \Gls{Term} $t \in T(F, C)$ ist dann  {
\begin{itemize}
	\item{ein \Gls{Konstantensymbol}, also $t \in C$}
	\item{oder eine \emph{\Gls{Funktionsanwendung}} des Funktionssymbols $f \in F$ mit $\Const{arity}~f \in \{n, \omega\}$ 
		auf die \emph{\Glspl{Argument}} ${\tOneN \in T(F, C)}$, geschrieben ${t = (f, \tOneN)}$}
\end{itemize}}
In Mengenschreibweise:
$$T(F, C) \coloneqq C \cup \curl*{
(f, \tOneN)~|
~f\in F,~\Const{arity}~f~ \in \{n, \omega\},~ \tOneN \in T(F, C)
}$$ 
\end{definition}

Eine \Gls{Funktionsanwendung} wird in der Literatur oft mit dem Funktionssymbol außerhalb des Tupels geschrieben (\cite{buch1977}, \cite{NPHardMatching}), also $f(\tOneN)$ statt $(f, \tOneN)$. Zum deutlicheren Abheben von Funktionen, die auf Termen operieren, zu Termen selbst, wird diese Schreibweise hier keine Verwendung finden. 


\begin{figure}
\Tree [.\texttt{divide} 3 [.\texttt{sin} 1 ] ]
\label{ersterBeispielBaum}
\caption{Baumdarstellung des Terms $(\texttt{divide}, 3, (\texttt{sin}, 1))$ }
\end{figure}

\begin{beispiel}~\\
Beispielsweise lässt sich der Ausdruck $\frac 3 {\sin 1}$ in der formalen Schreibweise als Term mittels der Funktionssymbole $\texttt{sin}$ und $\texttt{divide}$ sowie den Konstantensymbolen $3$ und $1$ darstellen als $(\texttt{divide}, 3, (\texttt{sin}, 1))$. Ein Term kann als Baum\footnote{In der theoretischen Informatik auch Syntaxbaum oder AST (englisch für \textit{Abstract Syntax Tree})} aufgefasst werden, das aktuelle Beispiel in Abb. \ref{ersterBeispielBaum}.
\end{beispiel}

Mit dem Kontext der Baumdarstellung lassen sich nun die folgenden Begriffe auf Terme übertragen. In der Funktionsanwendung $t = (f, \tOneN)$ sind $\tOneN$ die \emph{Kinder} ihres \emph{\Glspl{Vater}} $t$. Ein \Gls{Kind} ist allgemeiner \emph{\Gls{Nachkomme}}. Nachkommen verhalten sich transitiv, also ein Nachkomme $z$ des Nachkommen $y$ von $x$ ist auch ein Nachkomme von $x$. Umgekehrt ist $x$ \emph{\Gls{Ahne}} von $y$ und $z$. \\




\section{Funktionsauswertung}
Die Erweiterung des Funktionssymbols zur Funktion, die von einem Raum $Y^n$ nach $Y$ abbildet, folgt mittels der $\Const{eval}$ Funktion frei nach O'Donnell \cite{buch1977}.

\begin{equation*}
    \begin{split}
	\Const{eval} &\colon \paren*{F \rightarrow \bigcup_{n \in \mathbb{N}} Y^n \rightarrow Y} \times (C \rightarrow Y) \rightarrow T \rightarrow Y\\
	\Const{eval} &(u, v)~t = \begin{cases}
		u~f~(\elems {\Const{eval}(u, v)~t} 1 n) & t = (f, \tOneN)\\
		v~t                                      & t \in C\\
		\end{cases}
    \end{split}
\end{equation*}
Gilt $\Const{arity}~f = n \in N$ für ein $f \in F$, ist zudem die Funktion $u~f \colon Y^n \rightarrow Y$ in ihrer Definitionsmenge auf Dimension $n$ eingeschränkt. 
Die Funktion $u$ wird als \emph{\Gls{Interpretation}} der Funktionssymbole $F$, die Funktion $v$ als Interpretation der Konstantensymbole $C$ und die Funktion $\Const{eval}(u, v) \colon T \rightarrow Y$ als Interpretation der Terme $T$ bezeichnet. 
Ein Element des Bildes einer Interpretation oder die Abbildung dahin wird als \emph{\Gls{Auswertung}} bezeichnet.
\\~\\

\begin{beispiel}~\\ \label{bEval}
Sei $F = \{\texttt{sum}, \texttt{prod}, \texttt{neg} \}$ und $C = \mathbb{N}$ mit $\Const{arity}~ \texttt{sum} = \Const{arity}~ \texttt{prod} = \omega$ und $\Const{arity}~ \texttt{neg} = 1$.
Für die Interpretation $\Const{eval}(u, v)$ können $u$ und $v$ so gewählt werden, dass jeder Term in $T$ zu einer ganzen Zahl $n \in \mathbb{Z}$ auswertbar ist.

\begin{equation*}
    \begin{split}
    u~\texttt{sum}  ~(\elems y 1 n) &=  \sum_{k = 1}^n y_k\\
    u~\texttt{prod} ~(\elems y 1 n) &= \prod_{k = 1}^n y_k\\
    u~\texttt{neg}~y &= -y\\
    &\\
    v~y &= y
    \end{split}
\end{equation*}

Hervorzuheben ist dabei, dass $u~\texttt{neg} \colon \mathbb Z \rightarrow \mathbb Z$ nur eine ganze Zahl als \Gls{Parameter} erwartet, während $u~\texttt{sum}$ und $u~\texttt{prod}$ Tupel ganzer Zahlen beliebiger Länge abbilden können.
Der Term $t = (\texttt{sum}, 3, (\texttt{prod}, 2, 4), (\texttt{neg}, 1))$ kann dann ausgewertet werden zu 
\begin{equation*}
    \begin{split}
    \Const{eval}(u, v)~t &= \Const{eval}(u, v) (\texttt{sum}, 3, (\texttt{prod}, 2, 4), (\texttt{neg}, 1)) \\
    &= u~\texttt{sum}~(\Const{eval}(u, v)~3, \Const{eval}(u, v)(\texttt{prod}, 2, 4),  \Const{eval}(u, v) (\texttt{neg}, 1)) \\
    &= u~\texttt{sum}~(v~3, u~\texttt{prod}~(\Const{eval}(u, v)~2, \Const{eval}(u, v)~4), u~\texttt{neg}~ (v~1)) \\
    &= u~\texttt{sum}~(3, u~\texttt{prod}~(v~2, v~4), u~\texttt{neg}~ 1) \\
    &= u~\texttt{sum}~(3, u~\texttt{prod}~(2, 4), -1) \\
    &= u~\texttt{sum}~( 3, 8, -1) \\
    &= 10 \\
    \end{split}
\end{equation*}
\end{beispiel}


\subsection{Konstruktor}
Eine direkt aus der Struktur des Terms folgende Interpretation $u_c$ für Funktionssymbole ist die des \emph{\Glspl{Konstruktor}}. Als Konstruktor eines Typs $A$ wird allgemein eine Funktion bezeichnet, die nach $A$ abbildet. Für typlose Terme ist diese Definition deshalb unzureichend. 
Insbesondere in funktionalen Sprachen wird das Konzept allerdings noch verfeinert. In Haskell transformiert ein Konstruktor Daten nicht im eigentlichen Sinn, sondern bündelt lediglich ein Tag, das festhält, welcher Konstruktor genutzt wurde, mit den $n$ übergebenen Argumenten zu einem Tupel der Größe $n+1$ \cite{haskellConstructor}. Das entspricht exakt der Funktionsanwendung in einem Term, mit dem Funktionssymbol als Tag. Dementsprechend folgt die Definition des Konstruktors.

\begin{definition}~\\
Die Interpretation $u_c$ angewendet auf ein Funktionssymbol $f$ bildet das $n$-Tupel von Argumenten auf eine Funktionsanwendung von $f$ mit den selben $n$ Argumenten ab. 
 Mit $f \in F$ und $\Const{arity}~f = n \in \mathbb N$ 
gilt 
$$u_c~f \colon T^n \rightarrow T, ~(\tOneN) \mapsto (f, \tOneN)$$
\end{definition}

Mit einem beliebigen $v \colon C \rightarrow C'$ ändert die Interpretation {$\Const{eval}(u_c, v) \colon T(F, C) \rightarrow T(F, C')$} damit nur die Konstantensymbole eines Terms, lässt aber die sonstige Struktur unverändert. Insbesondere ist $\Const{eval}(u_c, v) \colon T \rightarrow T$ mit $v~y = y$ die Identität.
Die Interpretation $u_c$ reicht für bestimmte Funktionssymbole aus, etwa kann so das Funktionssymbol $\texttt{pair}$ ein Paar als Term darstellen.
$$u_c~\texttt{pair} \colon T^2 \rightarrow T, ~(a, b) \mapsto (\texttt{pair}, a, b)$$
Äquivalent ist die Darstellung endlicher Mengen und Tupel mit den variadischen Funktionssymbolen \texttt{set} und \texttt{tup} möglich\footnote{Da eine Menge ihren Elementen keine Reihenfolge gibt, muss $u_c~\texttt{set}$ im Unterschied zu $u_c~\texttt{tup}$ prinzipiell nicht die ursprüngliche Argumentreihenfolge erhalten. In Kapitel \ref{subsecNormalSortieren} wird eine Größenrelation zur möglichen Umordnung diskutiert.}. 
Hoffmann und O'Donnell \cite{hoffmann1982programming} definieren den Konstruktor im selben Kontext.


\begin{beispiel}~\\
Ein Graph $G = (V, E)$ wird als Paar der Menge von Knoten $V$ und Menge der Kanten $E$ definiert. Eine Kante ist dabei eine zweielementige Menge von Knoten. Der vollständige Graph auf drei Knoten ist $K_3 = \paren*{\{1, 2, 3\}, \curl*{\{1, 2\}, \{2, 3\}, \{1, 3\}}}$. Mit der Interpretation der Funktionssymbole $\texttt{pair}$ und $\texttt{set}$ als Konstruktoren lässt sich $K_3$ auch als Term darstellen:
$$(\texttt{pair}, (\texttt{set}, 1, 2, 3), (\texttt{set}, (\texttt{set}, 1, 2), (\texttt{set}, 2, 3), (\texttt{set}, 1, 3))).$$
\end{beispiel}





\section{Muster} \label{subsecMuster}

Bisher wurden die Objekte beschrieben, die in dieser Arbeit transformiert werden sollen. Die Transformationsregeln selbst lassen sich allerdings auch als Paare von bestimmten Termen darstellen. Zur Abgrenzung beider Konzepte werden die zu transformierenden Terme $t\in T(F, C)$ von hier an \emph{\Gls{Literal}} genannt. Terme, die  Teil einer Regeldefinition sind, werden \emph{\Gls{Muster}} genannt. Die Menge der Muster $M(F, C)$ ist eine Obermenge der Literale, da sie deren Konstantensymbole um die Menge der \emph{\Glspl{Mustervariable}} $X$ erweitert\footnote{Die Ergänzung der Funktionssymbole um Mustervariablen ist genau so möglich, wird aber vor allem, um die Notation übersichtlich zu halten, in den späteren Kapiteln nicht verfolgt.}. Konkrete Elemente $\mathbf x \in X$ werden im folgenden \textbf{fett} geschrieben.
$$M(F, C) \coloneqq T(F, C \cup X)$$

Eine \emph{\Gls{Ersetzungsregel}} für Literale $t \in T(F, C)$ hat die Form $(l, r) \in M(F, C) \times M(F, C)$. Die linke Seite $l$ steht für das Muster, welches im Literal durch einen Ausdruck der Form der rechten Seite $r$ ersetzt werden soll. Für die bessere Lesbarkeit wird statt $(l, r)$ auch $l \mapsto r$ geschrieben.

\begin{beispiel}~\\ \label{bMuster}
Die Regel, die die Summe zweier identischer Terme $x$ als Produkt von $2$ und $x$ transformiert, wird geschrieben als
$$(\texttt{sum}, \mathbf x, \mathbf x) \mapsto (\texttt{prod}, 2, \mathbf x).$$
In der Anwendung auf das Literal 
$t = (\texttt{sum}, (\texttt{sin}, 3), (\texttt{sin}, 3))$, wird $t$ zu $t' = (\texttt{prod}, 2, (\texttt{sin}, 3))$ transformiert. 
Hervorzuheben ist dabei, dass die Mustervariable $\mathbf x$ selbst nicht mehr im Ergebnisterm vorkommt. Sie wurde durch den Teilterm ersetzt, der im Ursprungsliteral an der Stelle von $\mathbf x$ stand, nämlich $(\texttt{sin}, 3)$.
\end{beispiel}

\begin{definition}~\\ \label{defMatch}
Für ein Paar $(p, t) \in M(F, C) \times T(F, C)$ ist eine Funktion $v_p \colon X \rightarrow T(F, C)$ ein \emph{\Gls{Match}}, wenn folgendes gilt:
$$\Const{eval}(u_c, \tilde v_p)~ p = t$$
$$\tilde v_p~ c = \begin{cases}
	v_p~ c & c \in X\\
	c      & c \in C \setminus X
\end{cases}$$
$v_p$ muss die Mustervariablen in $p$ so durch Literale ersetzen, dass ein Term identisch zu $t$ entsteht. 
Im vorangegangenen Beispiel \ref{bMuster} gilt damit $v_p~ \mathbf a = (\texttt{sin}, 3)$.

Im Folgenden wird der Begriff des Matches noch etwas weiter gefasst. Es werden nach wie vor die Mustervariablen durch Literale ersetzt, allerdings muss nicht direkt das Ergebnis der Ersetzung, sondern nur eine normalisierte Form des Ergebnisses mit dem Literal $t$ übereinstimmen:
$$\Const{lit}(v_p, p)  = t$$
mit 
$$\Const{lit}(v_p, p) \coloneqq \Const{normalize}~(\Const{eval}(u_c, \tilde v_p)~ p).$$
Die Funktion $\Const{lit} \colon \paren*{X \rightarrow T} \times M \rightarrow T$ wird als \emph{\Gls{Musterinterpretation}} bezeichnet.
Aus der Definition ist klar, dass $\Const{normalize} \colon T \rightarrow T$ Terme auf Terme abbildet und ein Match $v_p$ nur dann gefunden werden kann, wenn $t$ im Bild von $\Const{normalize}$ liegt. 
Gedacht ist $\Const{normalize}$ als Mittel, um Unterschiede zwischen Termen zu reduzieren, die die Auswertung für eine gegebene Interpretation $\Const{eval}(u, v)$ nicht ändern. Da das Ergebnis von $\Const{normalize}$ aber nur von dem übergebenen Term abhängig ist, können nie direkt Unterschiede zwischen mehreren Termen verglichen und missachtet werden. Ist die normalisierte Form $t'$ eines Terms $t$ ein Fixpunkt von $\Const{normalize}$, ist in dem Kontext klar, dass $t$ und $t'$ die gleiche Auswertung mit der Interpretation $\Const{eval}(u, v)$ besitzen, da auch $\Const{normalize}~t' = \Const{normalize}~t$ gilt. Wäre $\Const{normalize}~t' \neq t'$, würde die Funktion nicht die ihr zugedachte Aufgabe erfüllen. Deshalb muss $\Const{normalize}$ eine Projektion sein, also eine Funktion, für die jeder Bildpunkt gleichzeitig ein Fixpunkt ist. 

Welche Unterschiede $\Const{normalize}$ beseitigt, soll hier nicht festgelegt werden. Klar ist aber, dass je nach Wahl von $\Const{normalize}$ zwar ein einzelnes Muster sehr mächtig werden kann, also ein Match mit sehr vielen Termen möglich ist, das Finden des Matches im allgemeinen Fall allerdings immer aufwändiger wird. 

\end{definition}

Ein \emph{\Gls{Matchalgorithmus}} ist eine Vorgehensweise für ein gegebenes Paar {$(p, t) \in M(F, C) \times T(F, C)$} ein gültiges Match zu finden. Perfekt wird ein solcher Algorithmus dann genannt, wenn jedes mögliche Match gefunden wird.


