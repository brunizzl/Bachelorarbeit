
\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Entwicklung eines Termersetzungssystems für assoziative und kommutative Ausdrücke zum vereinfachen arithmetischer Terme\\ \textit{Version 0.0.1}}
\author{Bruno Borchardt}
\date{heute}

\usepackage{graphicx}
\usepackage[ngerman]{babel}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsmath} %  \begin{cases}  Wert 1 & Bedingung 1 \\ Wert 2 & Bedingung 2 \\ \end{cases} 
\usepackage{qtree}
\usepackage{algorithm}
\usepackage{algpseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\usepackage[backend=biber, style=alphabetic]{biblatex}
\addbibresource{quellen.bib}
%\bibliographystyle{plain}
%\bibliography{references}

\usepackage{xcolor} %\textcolor{blue}{This is a sample text in blue.}

\DeclarePairedDelimiter\paren{(}{)}
\DeclarePairedDelimiter\curl{\{}{\}}

\begin{document}

\maketitle

\tableofcontents

\clearpage
%\cleardoublepage <- für andere Dokumenttypen

\section{Einleitung}
\textcolor{red} {
\begin{itshape}
Anmerkung: Hier kommt hin, was halt in eine Einleitung soll:
\begin{itemize}
    \item was ist ein Termersetzungssystem?
    \item Einsatz von Termersetzungssystemen
    \begin{itemize}
        \item Beweisprüfer /Beweisassistenten
        \item Arithmetikausdrücke vereinfachen
        \item Optimierender Compiler
	\item Interpreter funktionaler Sprachen
        \item bestimmt noch mehr
    \end{itemize}
    \item was soll die in dieser Arbeit umgesetzte Variante (gut) können?
\end{itemize}
\end{itshape}
}

\section{Definitionen}

\subsection{Term}
Eine Menge von Termen $T$ ist in dieser Arbeit immer  in Abhängigkeit der Mengen $F$ und $C$, sowie der Stelligkeitsfunktion $\mathrm{arity} \colon F \rightarrow \mathbb{N} \cup \{\omega\}$.
$$T(F, C) \coloneqq C \cup \curl*{
(f, t_1, \dots, t_n)
~|
~f\in F,
~\mathrm{arity}(f) \in \{n, \omega\},
~ t_1, \dots,t_n \in T(F, C)
}$$ 
Elemente $f\in F$ werden \emph{Funktionssymbole} genannt. Ist $\mathrm{arity}(f) = \omega$, wird $f$ als \emph{variadisches} Funktionssymbol bezeichnet. Elemente $c \in C$ werden als Konstantensymbole bezeichnet.
Wichtig ist, dass vorerst nicht zwischen einem Konstantensymbol $c \in C$ unterschieden wird, welches bekannte Eigenschaften hat, etwa der Komplexen Zahl $c = -5i$ und einem Symbol, wessen Eigenschaften vom Kontext abhängen können, etwa dem Zeichen $c = \mathrm x$ (vorrausgesetzt $-5i,~\mathrm x \in C$). \\
 $(f, t_1, \dots, t_n) \in T$ wird auch als $f(t_1, \dots, t_n)$ geschrieben und \emph{Funktionsanwendung} von $f$ auf die \emph{Parameter} $t_1, \dots, t_n$ genannt. $t_1, \dots, t_n$ sind zudem die \emph{Kinder} ihres \emph{Vaters} $f(t_1, \dots, t_n)$. Kinder sind allgemeiner \emph{Nachkommen}. Nachkommen verhalten sich transitiv, also ein Nachkomme $z$ des Nachkommen $y$ von $x$ ist auch ein Nachkomme von $x$. Umgekehrt ist $x$ \emph{Ahne} von $y$ und $z$. \\
Häufig werden Abschnitte der Parameter einer Funktionsanwendung beliebiger Länge der Form $t_i, \dots, t_k$ vorkommen. Kompakt wird $ts...$ für den (möglicherweise leeren) Abschnitt des Funktionsanwendungstupels geschrieben. \\$f(t_1, \dots, t_k, a, t_{k+2}, \dots, t_n)$ kann also äquivalent $f(ts..., a, rs...)$ geschrieben werden, mit $(t_1, \dots, t_k) = (ts...)$ und $(t_{k+2}, \dots, t_n) = (rs...)$.\\~\\


\begin{figure}
\Tree[.f
	b
	[.g 
		[.f a ]
		b ]]
\label{ersterBeispielBaum}
\caption{Baumdarstellung des Terms $f(b, g(f(a), b))$ }
\end{figure}

\textbf{Beispiel}\\
Sei $F = \{f, g\}$ und $C = \{a, b, c\}$ sowie $\mathrm{arity}(f) = \omega$ und $\mathrm{arity}(g) = 2$.\\
$t = f(b, g(f(a), b)) \in T(F, C)$ ist ein Term, dargestellt in Abb. \ref{ersterBeispielBaum}. $b$ ist ein Kind von $\tilde{t} = g(f(a), b)$ und ein Ahne von $t$.

\subsection{Funktionsauswertung}
Ein Funktionssymbol ist in der allgemeinen Definition eines Terms noch keine Funktion, da die Abbildungsvorschrift, sowie Definitionsmenge und Bildmenge nicht definiert sind. Eine Funktionsanwendung wird primär als Datenstruktur gesehen, etwa die des binären Funktionssymbols $pair$ auf die zwei Parameter $a$ und $b$ als ein Paar: $pair(a, b)$ oder die des variadischen Funktionssymbols $set$ als Darstellungsmöglichkeit für endliche Mengen innerhalb eines Terms.\\
Die Erweiterung des Funktionssymbols zur Funktion, die von einem Raum $Y^n$ nach $Y$ abbildet, folgt mittels der $\mathrm{eval}$ Funktion frei nach \cite{buch1977}.

\textcolor{red}{\textit{Der Name $T_Y$ ist noch work in progress.}}
$$T_Y \coloneqq \{(f, y_0, \dots, y_{n-1})~|~f \in F,~\mathrm{arity}(f) \in \{n, \omega\},
~ y_0, \dots,y_{n-1} \in Y\}$$
\begin{equation*}
    \begin{split}
	\mathrm{eval} &\colon (T_Y \rightarrow Y) \times (C \rightarrow Y) \rightarrow T \rightarrow Y\\
	\mathrm{eval} &(u, v)(t) = \begin{cases}
		u(f, \mathrm{eval}(u, v)(t_0), \dots, \mathrm{eval}(u, v)(t_{n-1})) & t = f(t_1, \dots, t_n)\\
		v(c)                                                                                            & t = c
		\end{cases}
    \end{split}
\end{equation*}

Das Paar $(u, v) \in (T_Y \rightarrow Y) \times (C \rightarrow Y)$ wird dabei als \emph{Interpretation} von $T$ bezeichnet. Die Funktion $\mathrm{eval}(u, v)$ ist eine \emph{Auswertung}. 

Die Definition von $\mathrm{eval}(u, v)$ als echte Funktion ist im folgenden manchmal zu restriktiv, da die für diese Arbeit interessanten Terme auch Symbole beinhalten können, deren Wert in $Y$ nicht bekannt ist, etwa enthält der Term $+(1, a)$ ein nicht weiter spezifiziertes Symbol $a \in C$. Analog sollen an dieser Stelle auch Funktionssymbole $f \in F$ nicht ausgeschlossen werden, die keine bekannte Interpretation haben. $u$ und $v$ dürfen damit auch echte partielle Funktionen sein, womit auch $\mathrm{eval}(u, v)$ kontextabhängig als partielle Funktion angenommen wird.
\\~\\

\textbf{Beispiel}\\
Sei $F = \{+, \cdot \}$ und $C = \mathbb{N}$ mit $\mathrm{arity}(f) = \omega$ für $f\in \{+, \cdot \}$.
Als Interpretation kann dann die Auswertung des Terms zu den natürlichen Zahlen gewählt werden, wobei $\mathrm{id}$ für die Identitätsfunktion steht.
$$u(f, y_0, \dots, y_{n-1}) = \begin{cases}
\Sigma_{i = 0}^{n-1} y_i & f = +\\
\Pi_{i = 0}^{n-1} y_i & f = \cdot\\
\end{cases}$$
$$v = \mathrm{id}$$
Der Term $t = +(3, \cdot(2, 4))$ kann dann ausgewertet werden zu 
\begin{equation*}
    \begin{split}
    \mathrm{eval}(u, v)(t) &= \mathrm{eval}(u, v)(+(3, \cdot(2, 4))) \\
    &= u(+, \mathrm{eval}(u, v)(3), \mathrm{eval}(u, v)(\cdot(2, 4))) \\
    &= u(+, v(3), u(\cdot, \mathrm{eval}(u, v)(2), \mathrm{eval}(u, v)(4))) \\
    &= u(+, v(3), u(\cdot, v(2), v(4))) \\
    &= u(+, 3, u(\cdot, 2, 4)) \\
    &= u(+, 3, 8) \\
    &= 11 \\
    \end{split}
\end{equation*}

\section {Erste Normalform}

Das Kernthema dieser Arbeit ist die Vereinfachung von Termen. Eine Vereinfachung ist allerdings nur gültig, sofern sich die Bedeutung des vereinfachten Terms gegenüber der des ursprünglichen Terms nicht geändert hat. Da ein Term in sich keine Bedeutung trägt, muss eine Vereinfachung immer in Bezug auf eine Interpretation gesehen werden. Etwa kann der Ausdruck $X A X^{-1}$ zu $A$ vereinfacht werden, wenn $X, A \in \mathbb{C} \setminus \{0\}$, allerdings ist die Vereinfachung allgemein nicht möglich, sollten die Symbole $X$ und $A$ für Matritzen stehen. \\
Im folgenden wird von der Assoziativität oder Kommutativität bestimmter Funktionssymbole gesprochen. Diese ist immer im Kontext einer entsprechenden Interpretation zu sehen. Gleichzeitig ist aber auch klar, dass unabhängig von der Interpretation verschiedene Funktionssymbole die Rolle der Multiplikation übernehmen müssen, sollte sowohl skalare Multiplikation als auch Matrixmultiplikation im selben Term möglich sein. \\

In diesem Abschnitt werden erste Termumformungen beschrieben, die isolierte Eingenschaften einzelner Funktionen ausnutzen. Ziel ist es kommutative und assoziative Funktionsanwendungen eindeutig darzustellen.\\

\subsection {Assoziative Funktionsanwendungen}
Die geschachtelte Anwendung einer assoziativen Funktion führt je nach Klammersetzung zu verschiedenen mathematisch equivalenten Termen. Als Beispiel dient hier die Addition, dargestellt als Anwendung des Funktionssymbols $+$. Die folgenden Ausdrücke sind paarweise verschiedene Terme, jedoch alle mathematisch äquivalent.
\begin{equation*}
	\begin{split}
	+(+(+(a, b), c), d) &= +(+(a, +(b, c)), d)\\
	&= +(+(a, b), +(c, d))\\
	&= +(a, +(b, +(c, d)))\\
	&= \dots \\
	\end{split}
\end{equation*}
Es gibt mehrere Optionen eine solche Schachtelung in einem Term zu normalisieren, also in eine eindeutige Form zu bringen. Die erste ist, festzulegen, dass höchstens einer der beiden Parameter der binären assoziativen Funktion wieder Ergebnis dieser Funktion sein darf. Wählt man den zweiten Parameter dafür aus, ist wird die Summe in der Normalform dargestellt als $+(a, +(b, +(c, d)))$. Diese Methode nennt sich Pivotisierung und wird in \textcolor{red}{\textbf{Quellen}} näher untersucht.\\
Alternativ kann man die Summe von zwei Parametern auch als Spezialfall einer Summe von $n \in \mathbb{N}$ Parametern auffassen, dann gewohnt geschrieben als $\Sigma_{x \in \{a, b, c, d\}} x$. Dieser Weg wird im folgenden gewählt, wobei die Darstellung als Term dann $+(a, b, c, d)$ ist. Assoziative Funktionen sind in der gewählten Darstellung damit variadisch. \\
Die Normalisierung von Funktionsanwendungen des assoziativen Funktionssymbols $f$ bedeutet dann geschachtelte Funktionsanwendungen in eine Funktionsanwendung zu übersetzen. 
$$f(as..., f(bs...), cs...) \rightarrow f(as..., bs..., cs...)$$
Die Funktion $u \colon T_C \rightharpoonup C$ kann in den Algorithmen dieses Kapitels als Teil der partiellen Interpretation $(u, \mathrm{id})$ gesehen werden. 

\begin{algorithm}
\caption{$\mathrm{flatten} \colon T \times (T_C \rightharpoonup C) \rightarrow T$}\label{flatten}
\begin{algorithmic}[1] %[1] -> jede zeile nummeriert
\Require $t \in T(F, C)$, $u \in (T_C \rightharpoonup C)$
\If {$t = f(t_1, \dots, t_n)$ mit $f$ assoziativ in $u$}
	\While {$t = f(as..., f(bs...), cs...)$}
		\State $t \leftarrow f(as..., bs..., cs...)$
	\EndWhile
\EndIf
\State \textbf{return} $t$ 
\end{algorithmic}
\end{algorithm}

\subsection{Kommutative Funktionsanwendungen}
Eine Normalform für kommutative Funktionsanwendungen erfordert eine totale Ordnung auf der Menge aller Terme $T(F, C)$. Aufbauend auf einer totalen Ordnung von $F$ sowie $C$, kann eine lexikographische Ordnung von $T$ wie folgt definiert werden. 
\begin{itemize}
	\item{sind $s, \tilde{s} \in T$ Konstantensymbole, so ist die Ordnung identisch zu der Ordnung in $C$}
	\item{sind $s, a, \in T$ sowie $s$ ein Konstantensymbol und $a$ eine Funktionsanwendung gilt $s < a$ }
	\item{sind $a = f(ts...), b = g(rs...) \in T$ Funktionsanwendungen und ist $f \neq g$ gilt $a < b \iff f < g $}
	\item{sind $a = f(t_1, \dots, t_n), b = f(r_1, \dots, r_m) \in T$ Funktionsanwendungen, und $\tilde{t_1}, \dots, \tilde{t_n}$, $\tilde{r_1}, \dots, \tilde{r_m}$ die normalisierten Parameter von $a$ und $b$, ist die Ordnung wiefolgt}
	\begin{itemize}
		\item{wenn $\exists k \leq \min{(n, m)} \colon \forall i < k ~ \tilde{t_i} = \tilde{r_i} ,~ \tilde{t_k} \neq \tilde{r_k} $ gilt $a$ und $b$ sind geordnet wie $\tilde{t_k}$ und $\tilde{r_k}$}
		\item{ist $n < m$ und $\forall i < n\colon \tilde{t_i} = \tilde{r_i}$ gilt $a < b$}
		\item{ist $n = m$ und $\forall i \leq n\colon \tilde{t_i} = \tilde{r_i}$ gilt $a = b$}
	\end{itemize}
\end{itemize}
Zur Normalisierung einer kommutativen Funktionsanwendung werden zuerst alle Parameter normalisiert, dann können die Parameter nach der lexikographischen Ordnung von $T$ sortiert werden.

\subsection{Teilweise Auswertung}
Mit der Darstellung assoziativer Funktionen als variadische Funktionen, ist es möglich, dass eine Funktion teilweise ausgewertet werden kann, also gilt für assoziative Funktionssymbole $f \in F$
$$\mathrm{eval}(u, v)(f(a, b)) = c \in C \implies f(xs..., a, b, ys...) = f(xs..., c, ys...)$$
Ist $f$ zudem kommutativ gilt 
$$\mathrm{eval}(u, v)(f(a, b)) = c \in C \implies f(xs..., a, ys..., b, zs...) = f(xs..., c, ys..., zs...)$$
Eine normalisierte Funktionsanwendung ist so weit wie möglich ausgewertet. Sollte sie ganz ausgewertet werden können, ist die normalisierte Funktionsanwendung das Ergebnis der Auswertung. \\
Der Spezialfall ist eine assoziative Funktionsanwendung mit nur einem Parameter. Diese kann immer zu dem Parameter selbst normalisiert werden.

\begin{algorithm}
\caption{$\mathrm{combine} \colon T \times (T_C \rightharpoonup C) \rightarrow T$}\label{combine}
\begin{algorithmic}[1] %[1] -> jede zeile nummeriert
\Require $t \in T(F, C)$, $u \in (T_C \rightharpoonup C)$
\If {$\mathrm{eval}(u, \mathrm{id})(t) = c \in C$}
	\State \textbf{return} $c$ 
\ElsIf {$t = f(t_1, \dots, t_n)$ mit $f$ assoziativ in $u$}
	\If {$f$ kommutativ in $u$}
		\While {$t = f(xs..., a, ys..., b, zs...) \colon u(f(a, b)) = c \in C$}
			\State $t \leftarrow f(xs..., c, ys..., zs...)$
		\EndWhile
	\Else
		\While {$t = f(xs..., a, b, ys...) \colon u(f(a, b)) = c \in C$}
			\State $t \leftarrow f(xs..., c, ys...)$
		\EndWhile
	\EndIf
	\If {$t = f(t_1)$}
		\State \textbf{return} $t_1$ 
	\EndIf
\EndIf
\State \textbf{return} $t$ 
\end{algorithmic}
\end{algorithm}

\subsection{Kombination der einzelnen Vereinfachungen}
Der folgende Algorithmus kombiniert die einzelnen Überlegungen dieses Kapitels. 

\begin{algorithm}
\caption{$\mathrm{normalize} \colon T \times (T_C \rightharpoonup C) \rightarrow T$}\label{normalize}
\begin{algorithmic}[1] %[1] -> jede zeile nummeriert
\Require $t \in T(F, C)$, $u \in (T_C \rightharpoonup C)$
\If {$t = f(t_1, \dots, t_n)$}
	\For {$i \in \{1, \dots, n\}$}
		\State $t_i \leftarrow \mathrm{normalize}(t_i, u)$
	\EndFor
\EndIf
\State $t \leftarrow \mathrm{flatten}(t, u)$
\State $t \leftarrow \mathrm{combine}(t, u)$
\If {$t = f(t_1, \dots, t_n)$ mit $f$ kommutativ in $u$}
	\State sortiere $t_1, \dots, t_n$ lexikographisch
\EndIf
\State \textbf{return} $t$ 
\end{algorithmic}
\end{algorithm}

\section{Patternmatching}
Im vorigen Abschnitt wurde eine erste Normalform für Terme definiert. Alle Vereinfachungen, die dort behandelt wurden, sind recht einfach und direkt zu implementieren, da nur auf lokale Eigenschaften des zu vereinfachenden Terms Rücksicht genommen werden muss. In diesem Abschnitt wird beschrieben, wie ein Term auch zuverlässig auf komplexere Muster geprüft werden kann, so dass nach Implementierung der Mustererkennung selbst jede einzelne Vereinfachungsregel durch zwei Muster beschrieben werden kann: ein Muster gibt an, welche Struktur im zu vereinfachenden Term gesucht wird, ein zweites Muster gibt an, zu was diese Struktur transformiert wird. Ein Beispiel für ein solches Musterpaar ist etwa die Anwendung der ersten binomischen Formel:
$$a^2 + 2 a b + b^2 \rightarrow (a + b)^2$$
In der etablierten Schreibweise als Term dann geschrieben als:
$$sum(pow(a, 2), product(2, a, b), pow(b, 2)) \rightarrow pow(sum(a, b), 2)$$
Die Zeichen $a$ und $b$ stehen dabei nicht für Elemente in $C$, sondern dienen lediglich als Platzhalter für beliebige Teilterme, wobei die verschiedenen Vorkommnisse des selben Zeichens immer auch mit gleichen Termen assoziiert werden müssen. Ein solches Zeichen wird im folgenden \emph{Mustervariable} genannt.

\subsection{Muster}
Eine Menge von Termen $T(F)$ kann durch Vereinigung von $C$ mit der Menge der Mustervariablen $X$ zu einer Menge von Mustertermen $M$ erweitert werden. 

$$M(F, C) \coloneqq T(F, C \cup X)$$

Eine drei-Tupel $(m, v_m, t) \in M \times (X \rightarrow T) \times T$ wird als \emph{Match} bezeichnet, wenn $\mathrm{normalize}(\mathrm{eval}(\mathrm{id}, \tilde v_m)(m))= t$ gilt, wobei $\tilde v_m(x) = v_m(x)$ für $x \in X$ und $\tilde v_m(c) = c$ für $c \in C$. Jedes Literal ist damit Fixpunkt von $\mathrm{eval}(\mathrm{id}, \tilde v_m)$, wohingegen Mustervariablen auf Nachkommen von $t$ abgebildet werden. 
Klar ist auch, dass ein Match nur für bereits normalisierte Literale $t$ existieren kann, zudem werden Muster in Matches immer als bereits normalisiert angenommen.\\
Wichtig ist in dem Zusammenhang der Unterschied zwischen der \emph{Musterinterpretation} $(\mathrm{id}, \tilde v_m)$, welche Musterterme als Literale interpretiert und einer Interpretation $(\hat{u}, \hat{v})$ der Literale selbst. Diese zweite Interpretation wird im folgenden als gegeben angenommen. Erneut bezieht sich Kommutativität von Funktionssymbolen dann auf diese meist implizite Interpretation $(\hat u, \hat v)$.\\

Eine \emph{Matchfunktion} ist eine Funktion, die zu einem Paar $(m, t) \in M \times T$ eine Menge von Funktionen der Form $v_m \colon X \rightarrow T$ findet, so dass $(m, \tilde{v}_m, t)$ ein Match ist, mit . Sei dabei $\mathcal{P}(A)$ die Potenzmenge der Menge $A$.
$$\mathrm{match} \colon M \times T \rightarrow \mathcal{P}(X \rightarrow T)$$

Die triviale Matchfunktion, welche jedes Paar $(m, t)$ auf die leere Menge abbildet, wird hier nicht weiter betrachtet.

\subsection{Perfekte Matchfunktion}
Die Matchfunktion, die die Menge aller gültigen Funktionen $v_m$ zurückgibt, wird $\mathrm{match}^*$ oder perfekte Matchfunktion genannt.

\begin{algorithm}
\caption{$\mathrm{match}^* \colon M \times T \rightarrow \mathcal{P}(X \rightarrow T)$}\label{perfectMatch}
\begin{algorithmic}[1] %[1] -> jede zeile nummeriert
\Require $m \in M$, $t \in T$
\If {$m \in X$}
	\State \textbf{return} $\{v \in (C \cup X \rightarrow T) ~|~ v(m) = t\}$ 
\EndIf
\If {$m = f(m_1, \dots, m_n)$ und $t = f(t_1, \dots, t_n)$}
	\If {$f$ kommutativ}
		\State $V \leftarrow \emptyset$
		\ForAll {$(\tilde m_1, \dots, \tilde m_n)$ permutation von $(m_1, \dots, m_n)$}
			\State $V \leftarrow V \cup \bigcap_{i = 1}^n {\mathrm{match}^*(\tilde m_i, t_i)}$
		\EndFor
		\State \textbf{return} $V$
	\Else
		\State \textbf{return} $\bigcap_{i = 1}^n {\mathrm{match}^*(m_i, t_i)}$
	\EndIf
\EndIf
\State \textbf{return} $\emptyset$
\end{algorithmic}
\end{algorithm}
\textcolor{red}{\textit{TODO: Laufzeit von $\mathrm{match}^*$ (Spoiler: nicht so premium)}}

\section{Termersetzungssystem}
\textcolor{red}{
\begin{itshape}
Anmerkung: Dieses Kapitel wird recht kurz und ist auch als Unterkapitel von Patternmatching denkbar. 
Während in Patternmatching (bisher) immer nur mit einem Muster und dem Gesamtterm gematcht wird, Werden hier mehrere Muster auf jeden Teilterm angewendet, bis keine Anwendung mehr möglich ist
\end{itshape}
}

\section{Umsetzung in C\texttt{++}}
\textcolor{red}{
\begin{itshape}
Anmerkung: Hier wird erläutert, wie meine konkrete Implementierung Terme speichert und verwaltet und wie die Algorithmen konkret umgesetzt sind. Vielleicht auch noch wo anders im Text anzufinden, aber auch jeden Fall auch hier ist meine Implementierung der Lambdafunktion als Term, was die Vereinfachungsmuster noch etwas ausdrucksstärker macht. Dann gibt es noch spezielle Matchvariablen, die darauf optimiert sind bestimmte Werte zu matchen, die werde ich an dieser Stelle auch erläutern, mathematisch rigoros ist mir das glaube ich zu aufwendig.
Mögliche Tangenten:
\begin{itemize}
\item {Ausflug in die Codegenerierung mit Templates für Funktionen, die genau ein Muster matchen (ist ein recht tiefes Kanienchenloch)}
\item {Meine Idee (und Umsetzung) einer Art Aufzählung (in cpp und Co. als enum in der Sprache enthalten), die Hierarchien erlaubt und damit Basis eines (wie ich finde) relativ eleganten Typsystems für die einzelnen Arten von Termknoten darstellt}
\item {Idee und Umsetzung eines sehr einfachen Typsystems}
\item {Speichermanagement}
\end{itemize}
\end{itshape}
}


\section{Vereinfachen von Arithmetischen Termen}
\begin{itshape}
\textcolor{red} {Anmerkung zur Anmerkung: ab hier sind es nur noch Anmerkungen, da wird Farbe gespart.}
Anmerkung: Ich habe begonnen das Termersetzungssystem zu entwickeln, um Arithmetische Ausdrücke zu vereinfachen (etwa $a + 2 a \rightarrow 3 a$). Wie genau ich das umsetze, wird in diesem Abschnitt erläutert.
\\Während die Datenstruktur und der Matchingalgorithmus schon benutzbar sind, ist dieser Teil von mir bisher so gut wie gar nicht implementiert worden. Der grobe Plan ist aber folgender:
\begin{enumerate}
    \item Funktionen höherer Ordnung anwenden:
    \begin{itemize}
        \item ableiten (Prototyp dafür steht schon)
        \item vielleicht integrieren (soll für den allgemeinen Fall wohl schwer sein)
        \item vielleicht fouriertransformieren
        \item vielleicht laplacetransformieren
        \item ganz ganz ganz ganz vielleicht Differentialgleichungen lösen
    \end{itemize}
    \item Normalform herstellen:
    \begin{itemize}
        \item alles ausmultiplizieren ($a\cdot (b + c) \rightarrow a\cdot b + a\cdot c$)
        \item Vorzeichen aus ungeraden Funktionen herausziehen ($\sin(-x) \rightarrow -\sin(x)$)
        \item Vorzeichen in geraden Funktionen auf plus setzen ($\cos(-x) \rightarrow \cos(x)$)
        \item Überlegen, wie man das selbe für Fälle mit Summen im Argument definiert ($\cos(a - b)$ vs. $\cos(b - a)$)
        \item bekannte Faktoren aus Potenz ziehen ($(3 x)^2 \rightarrow 9 x^2$)
        \item \dots
    \end{itemize}
    \item Vereinfachen:
    \begin{itemize}
        \item manche Transformationen sollten immer angewendet werden (etwa $\sin^2(x) + \cos^2(x) \rightarrow 1)$
        \item andere Transformationen nur ausprobieren und mit einer passenden Metrik gucken, wie gut ein Term nach Anwendung noch weiter vereinfacht werden kann (etwa, wenn man aus verschiedenen Optionen des Ausklammerns wählen kann)
        \item vielleicht Linearfaktorzerlegung von Polynomen (schätze ich für den allgemeinen Fall schwierig ein, solange ich nur exakte Operationen zulasse)
        \item vielleicht Polynomdivision (schätze ich genau so schwierig ein, zumindest wenn ich nicht vorher schon Linearfaktoren habe)
        \item \dots
    \end{itemize}
\end{enumerate}
~\\~
Anmerkung 1: Die Normalform ist notwendig, um zu garantieren, dass mehrfaches Auftreten eines Teilbaums / Teilterms auch erkannt wird. \\
Anmerkung 2: es kann sein, dass ich manche Eigenschaften der Normalformauch während des Vereinfachungsschrittes immer wieder wiederherstellen muss.

\subsection{Vergleich meiner Features mit anderen Computeralgebrasystemen}
Ich bin ja nicht der erste, der auf die Idee kommt, Terme zusammenzufassen. Wolphram Alpha und Maple sind zwar nicht Open Source, aber andere Optionen, wie etwa SymPy aus der Python Standardbibliothek soweit ich weiß schon. Da lässt sich bestimmt ein bisschen vergleichen, wie andere Leute die selben Probleme lösen.
\end{itshape}

\section{Zusammenfassung}
\begin{itshape}
Was halt in eine Zusammenfassung kommt
\end{itshape}


\printbibliography

\end{document}
