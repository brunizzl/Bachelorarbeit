
\documentclass{scrartcl}
\usepackage[utf8]{inputenc}

\title{Entwicklung eines Termersetzungssystems für assoziative und kommutative Ausdrücke zum vereinfachen arithmetischer Terme\\ \textit{Version 0.0.2}}
\author{Bruno Borchardt}
\date{\today}

\usepackage{csquotes}
\usepackage[ngerman]{babel}

\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsmath} %  \begin{cases}  Wert 1 & Bedingung 1 \\ Wert 2 & Bedingung 2 \\ \end{cases} 
\numberwithin{figure}{section} %label nr. beinhaltet section

\usepackage{qtree}
\usepackage{algorithm}
\usepackage{algpseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\usepackage[backend=biber, style=alphabetic]{biblatex}
\addbibresource{quellen.bib}
%\bibliographystyle{plain}
%\bibliography{references}

\usepackage{xcolor} %\textcolor{blue}{This is a sample text in blue.}

%\paren*{a + b} skaliert automatisch klammern um a + b
\DeclarePairedDelimiter\paren{(}{)} 
\DeclarePairedDelimiter\curl{\{}{\}}

\setlength{\parindent}{0pt} %keine Einrückung nach absatz

\usepackage{amsthm}
\theoremstyle{definition} %keine kursiven theoreme

%.........................................................................
%................................ Macros .................................
%.........................................................................

% baut teile eines tupels: "t_1, ..., t_n"
\newcommand{\elems}[3]{{#1}_{#2}, \dots, {#1}_{#3}}
\newcommand{\tOneN}{\elems t 1 n}

% stapelt zweiten parameter auf ersten
\newcommand{\stapel}[2]{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily {#2}}}}{#1}}}

%.........................................................................
%................................ Body ...................................
%.........................................................................
\begin{document}

\maketitle

\tableofcontents

\clearpage
%\cleardoublepage <- für andere Dokumenttypen

\section{Einleitung}
\textcolor{red} {
\begin{itshape}
Anmerkung: Hier kommt hin, was halt in eine Einleitung soll:
\begin{itemize}
    \item was ist ein Termersetzungssystem?
    \item Einsatz von Termersetzungssystemen
    \begin{itemize}
        \item Beweisprüfer /Beweisassistenten
        \item Arithmetikausdrücke vereinfachen
        \item Optimierender Compiler
	\item Interpreter funktionaler Sprachen
        \item bestimmt noch mehr
    \end{itemize}
    \item was soll die in dieser Arbeit umgesetzte Variante (gut) können?
\end{itemize}
\end{itshape}
}

Die Idee Computer zu nutzen um symbolische Ausdrücke zu manipulieren ist fast so alt wie der Computer selbst.  LISP \cite{lisp} ist als eine der ersten Programmiersprachen bereits für diesen Zweck geschaffen worden. 

\subsection{Zielsetzung}
Diese Arbeit hat zwei Ziele. Zum einen soll ein System entwickelt werden, welches kompakt formulierte Ersetzungsregeln auf einen Term anwenden kann. Daran angeknüpft soll dieses System dann genutzt werden um Terme zu vereinfachen. Ein vereinfachter Term hat dabei die selbe Bedeutung wie der ursprüngliche Term,  er ist allerdings hinsichtlich einer entsprechenden Bewertungsfunktion kleiner. Ein Beispiel für eine solche Bewertungsfunktion ist die Zählung der im Term vorkommenden Symbole, wobei Mehrfachnennungen auch mehrfach gezählt werden.


\newtheorem{b1}{Beispiel}[section]
\begin{b1}~\\
Mit den Vereinfachungsregeln
\begin{alignat*}{4}
    ~& a \cdot b + a \cdot c & &= a \cdot (b + c) &~~~& (1) \\
    ~& \sin(a)^2 + \cos(a)^2 & &= 1               &~~~& (2) \\
    ~& \paren{a^b}^c         & &= a^{b \cdot c}   &~~~& (3) \\
    ~& \sqrt{a}              & &= a^{\frac 1 2}   &~~~& (4)
\end{alignat*}
\end{b1}
kann folgende Transformation vorgenommen werden.
\begin{equation*}
    \begin{split}
	3 \cdot \sin(x + y)^2 + 3 \cdot \sqrt{\cos(x + y)^4} 
	&\stapel = {(1)} 3 \cdot \paren*{\sin(x + y)^2 + \sqrt{\cos(x + y)^4}} \\
	&\stapel = {(4)} 3 \cdot \paren*{\sin(x + y)^2 + \paren*{{\cos(x + y)^4}}^{\frac 1 2}}\\
	&\stapel = {(3)} 3 \cdot \paren*{\sin(x + y)^2 + {\cos(x + y)^2}}\\
	&\stapel = {(2)} 3
    \end{split}
\end{equation*}

\section{Grundlegende Definitionen}

\subsection{Term}
Eine Menge von Termen $T$ ist in dieser Arbeit immer  in Abhängigkeit der Mengen $F$ und $C$, sowie der \emph{Stelligkeitsfunktion} $\mathrm{arity} \colon F \rightarrow \mathbb{N} \cup \{\omega\}$ definiert. $F$ enthält die sogenannten \emph{Funktionssymbole}. Beispiele für mögliche Elemente in $F$ sind \texttt{sin} und \texttt{sqrt}, zudem auch Operatoren wie die Division, etwa geschrieben als \texttt{divide}. Die Stelligkeitsfunktion gibt für jedes Funktionssymbol an, wie viele Parameter erwartet werden. Eine mögliche Stelligkeit der genannten Beispielsymbole ist die folgende.

$$\mathrm{arity} f = \begin{cases}
2 & f  = \texttt{divide}\\
1 & f \in \{\texttt{sin}, \texttt{sqrt}\}\\
\end{cases}$$

Kann eine Funktionssymbol $f$ beliebig viele Parameter entgegennehmen, wird gesagt, dass $f$ \emph{variadische} Stelligkeit hat oder \emph{variadisch} ist. Die Stelligkeitsfunktion bildet $f$ dann auf $\omega$ ab. 

Die Menge $C$ enthält die \emph{Konstantensymbole}. Mit den genannten Beispielen für Funktionssymbole, ergibt etwa $C = \mathbb R$ Sinn. Wichtig ist allerdings, dass im folgenden nicht vorausgesetzt wird, dass jedem Konstantensymbol ein eindeutiger Wert zugeordnet werden kann\footnote{Die Symbole unbekannten Wertes werden häufig von den Konstantensymbolen getrennt und Variablensymbole genannt. Diese Unterscheidung wird hier nicht getroffen, vor allem um die später eingeführten Mustervariablen besser von Konstantensymbolen abzugrenzen.}.



Ein Term $t \in T(F, C)$ ist dann  {
\begin{itemize}
	\item{ein Konstantensymbol, also $t \in C$}
	\item{oder eine \emph{Funktionsanwendung} des Funktionssymbols $f \in F$ mit $\mathrm{arity} f \in \{n, \omega\}$ 
		auf die Terme ${\tOneN \in T(F, C)}$, geschrieben ${t = (f, \tOneN)}$}
\end{itemize}}
In Mengenschreibweise:
$$T(F, C) \coloneqq C \cup \curl*{
(f, \tOneN)~|
~f\in F,~\mathrm{arity}(f) \in \{n, \omega\},~ \tOneN \in T(F, C)
}$$ 
Eine Funktionsanwendung wird in der Literatur oft mit dem Funktionssymbol außerhalb des Tupels geschrieben \cite{buch1977}, also $f(\tOneN)$ statt $(f, \tOneN)$. Zum deutlicheren Abheben von Funktionen die Terme transformieren zu Termen selbst, wird diese Schreibweise hier keine Verwendung finden. 


\begin{figure}
\Tree [.\texttt{divide} 3 [.\texttt{sin} 1 ] ]
\label{ersterBeispielBaum}
\caption{Baumdarstellung des Terms $(\texttt{divide}, 3, (\texttt{sin}, 1))$ }
\end{figure}

\newtheorem{b2}[b1]{Beispiel}
\begin{b2}~\\
Als Beispiel lässt sich der Ausdruck $\frac 3 {\sin 1}$ in der formalen Schreibweise als Term mittels der Funktionssymbole $\texttt{sin}$ und $\texttt{divide}$, sowie den Konstantensymbolen $3$ und $1$ darstellen als $(\texttt{divide}, 3, (\texttt{sin}, 1))$. Ein Term kann dabei auch immer als Baum\footnote{In der theoretischen Informatik auch Syntaxbaum oder AST (englisch für \textit{Abstract Syntax Tree})} aufgefasst werden, etwa das aktuelle Beispiel in in Abb. \ref{ersterBeispielBaum} .
\end{b2}

Mit dem Kontext der Baumdarstellung lassen sich nun die folgenden Begriffe auf Terme übertragen. In der Funktionsanwendung $t = (f, \tOneN)$ sind $\tOneN$ die \emph{Kinder} ihres \emph{Vaters} $t$. Kinder sind allgemeiner \emph{Nachkommen}. Nachkommen verhalten sich transitiv, also ein Nachkomme $z$ des Nachkommen $y$ von $x$ ist auch ein Nachkomme von $x$. Umgekehrt ist $x$ \emph{Ahne} von $y$ und $z$. \\


\subsection{Funktionsauswertung}
Die Erweiterung des Funktionssymbols zur Funktion, die von einem Raum $Y^n$ nach $Y$ abbildet, folgt mittels der $\mathrm{eval}$ Funktion frei nach \cite{buch1977}.

\begin{equation*}
    \begin{split}
	\mathrm{eval} &\colon \paren*{F \rightarrow \bigcup_{n \in \mathbb{N}} Y^n \rightarrow Y} \times (C \rightarrow Y) \rightarrow T \rightarrow Y\\
	\mathrm{eval} &(u, v)~t = \begin{cases}
		u~f~(\elems {\mathrm{eval}(u, v)~t} 1 n) & t = (f, \tOneN)\\
		v~t                                      & t \in C\\
		\end{cases}
    \end{split}
\end{equation*}
Gilt $\mathrm{arity} f = n \in N$ für ein $f \in F$, ist zudem die Funktion $u~f \colon Y^n \rightarrow Y$ in ihrer Definitionsmenge auf Dimension $n$ eingeschränkt. 
Die Funktion $u$ wird als \emph{Interpretation} der Funktionssymbole $F$, die Funktion $v$ als Interpretation der Konstantensymbole $C$ und das Paar $(u, v)$ als Interpretation der Terme $T(F, C)$ bezeichnet. Die Funktion $\mathrm{eval}(u, v) \colon T \rightarrow Y$ ist eine \emph{Auswertung} nach $Y$. 
\\~\\

\newtheorem{b3}[b1]{Beispiel}
\begin{b3}~\\
Sei $F = \{\texttt{sum}, \texttt{prod}, \texttt{neg} \}$ und $C = \mathbb{N}$ mit $\mathrm{arity}~ \texttt{sum} = \mathrm{arity}~ \texttt{prod} = \omega$ und $\mathrm{arity}~ \texttt{neg} = 1$.
Die Interpretation $(u, v)$ kann so gewählt werden, dass jeder Term in $T$ zu einer ganzen Zahl auswertbar ist.

\begin{equation*}
    \begin{split}
    u~\texttt{sum}  ~(\elems y 1 n) &= \Sigma_{k = 1}^n y_k\\
    u~\texttt{prod} ~(\elems y 1 n) &=    \Pi_{k = 1}^n y_k\\
    u~\texttt{neg}~y &= -y\\
    &\\
    v~y &= y
    \end{split}
\end{equation*}

Hervorzuheben ist dabei, dass $u~\texttt{neg} \colon \mathbb Z \rightarrow \mathbb Z$ nur eine Ganze Zahl als Parameter erwartet, während $u~\texttt{sum}$ und $u~\texttt{prod}$ Tupel Ganzer Zahlen beliebiger Länge abbilden können.
Der Term $t = (\texttt{sum}, 3, (\texttt{prod}, 2, 4), (\texttt{neg}, 1))$ kann dann ausgewertet werden zu 
\begin{equation*}
    \begin{split}
    \mathrm{eval}(u, v)~t &= \mathrm{eval}(u, v) (\texttt{sum}, 3, (\texttt{prod}, 2, 4), (\texttt{neg}, 1)) \\
    &= u~\texttt{sum}~(\mathrm{eval}(u, v)~3, \mathrm{eval}(u, v)(\texttt{prod}, 2, 4),  \mathrm{eval}(u, v) (\texttt{neg}, 1)) \\
    &= u~\texttt{sum}~(v~3, u~\texttt{prod}~(\mathrm{eval}(u, v)~2, \mathrm{eval}(u, v)~4), u~\texttt{neg}~ 1) \\
    &= u~\texttt{sum}~(3, u~\texttt{prod}~(v~2, v~4), -1) \\
    &= u~\texttt{sum}~(3, u~\texttt{prod}~(2, 4), -1) \\
    &= u~\texttt{sum}~( 3, 8, -1) \\
    &= 10 \\
    \end{split}
\end{equation*}
\end{b3}

\newtheorem{defKonstruktor}[b1]{Definition}
\begin{defKonstruktor}~\\
Eine direkt aus der Struktur des Terms folgende Interpretation $u_c$ für Funktionssymbole ist die des \emph{Konstruktors}. Als Konstruktor eines Typen $A$ wird eine Funktion bezeichnet, die nach $A$ abbildet \cite{haskellConstructor}. Mit $f \in F$ und $\mathrm{arity} f = n \in \mathbb N$ 
gilt $$u_c~f \colon T^n \rightarrow T, ~(\tOneN) \mapsto (f, \tOneN)$$
Mit einem beliebigen $v \colon C \rightarrow C'$ ändert die Auswertung $\mathrm{eval}(u_c, v) \colon T(F, C) \rightarrow T(F, C')$ damit nur die Konstantensymbole eines Terms, lässt aber die sonstige Struktur unverändert. Insbesondere ist $\mathrm{eval}(u_c, v) \colon T \rightarrow T$ mit $v~y = y$ die Identität.

Die Interpretation $u_c$ reicht für bestimmte Funktionssymbole aus, etwa kann so das Funktionssymbol $\texttt{pair}$ ein Paar als Term darstellen.
$$u_c~\texttt{pair} \colon T^2 \rightarrow T, ~(a, b) \mapsto (\texttt{pair}, a, b)$$
Äquivalent ist die Darstellung endlicher Mengen und Vektoren mit variadischen Funktionssymbolen \texttt{set} und \texttt{vec} möglich.

\end{defKonstruktor}



\section {Erste Normalform}

Das Kernthema dieser Arbeit ist die Vereinfachung von Termen. Eine Vereinfachung ist allerdings nur gültig, sofern sich die Bedeutung des vereinfachten Terms gegenüber der des ursprünglichen Terms nicht geändert hat. Da ein Term in sich keine Bedeutung trägt, muss eine Vereinfachung immer in Bezug auf eine Interpretation gesehen werden. Etwa kann der Ausdruck $X A X^{-1}$ zu $A$ vereinfacht werden, wenn $X, A \in \mathbb{C} \setminus \{0\}$, allerdings ist die Vereinfachung allgemein nicht möglich, sollten die Symbole $X$ und $A$ für Matritzen stehen. \\
Im folgenden wird von der Assoziativität oder Kommutativität bestimmter Funktionssymbole gesprochen. Diese ist immer im Kontext einer entsprechenden Interpretation zu sehen. Gleichzeitig ist aber auch klar, dass unabhängig von der Interpretation verschiedene Funktionssymbole die Rolle der Multiplikation übernehmen müssen, sollte sowohl skalare Multiplikation als auch Matrixmultiplikation im selben Term möglich sein. \\

In diesem Abschnitt werden erste Termumformungen beschrieben, die isolierte Eingenschaften einzelner Funktionen ausnutzen. Ziel ist es kommutative und assoziative Funktionsanwendungen eindeutig darzustellen.\\

Häufig werden Abschnitte der Parameter einer Funktionsanwendung beliebiger Länge der Form $\elems t i k$ vorkommen. Kompakt wird $ts...$ für den (möglicherweise leeren) Abschnitt des Funktionsanwendungstupels geschrieben. Das $s$ in $ts...$ ist dann nicht als einzelnes Symbol zu lesen, sondern als Suffix um $t$ in den Plural zu setzen. \\$f(\elems t 1 k, a, \elems t {k+2} n)$ kann also äquivalent $f(ts..., a, rs...)$ geschrieben werden, mit $(\elems t 1 k) = (ts...)$ und $(\elems t {k+2} n) = (rs...)$.\\

\subsection {Assoziative Funktionsanwendungen}
Die geschachtelte Anwendung einer assoziativen Funktion führt je nach Klammersetzung zu verschiedenen mathematisch equivalenten Termen. Als Beispiel dient hier die Addition, dargestellt als Anwendung des Funktionssymbols $+$. Die folgenden Ausdrücke sind paarweise verschiedene Terme, jedoch alle mathematisch äquivalent.
\begin{equation*}
	\begin{split}
	+(+(+(a, b), c), d) &= +(+(a, +(b, c)), d)\\
	&= +(+(a, b), +(c, d))\\
	&= +(a, +(b, +(c, d)))\\
	&= \dots \\
	\end{split}
\end{equation*}
Es gibt mehrere Optionen eine solche Schachtelung in einem Term zu normalisieren, also in eine eindeutige Form zu bringen. Die erste ist, festzulegen, dass höchstens einer der beiden Parameter der binären assoziativen Funktion wieder Ergebnis dieser Funktion sein darf. Wählt man den zweiten Parameter dafür aus, wird die Summe in der Normalform dargestellt als $+(a, +(b, +(c, d)))$. Diese Methode nennt sich Pivotisierung und wird in \textcolor{red}{\textbf{Quellen}} näher untersucht.\\
Alternativ kann man die Summe von zwei Parametern auch als Spezialfall einer Summe von $n \in \mathbb{N}$ Parametern auffassen, dann gewohnt geschrieben als $\Sigma_{x \in \{a, b, c, d\}} x$. Dieser Weg wird im folgenden gewählt, wobei die Darstellung als Term dann $+(a, b, c, d)$ ist. Assoziative Funktionen sind in der gewählten Darstellung damit variadisch. \\
Die Normalisierung von Funktionsanwendungen des assoziativen Funktionssymbols $f$ bedeutet dann geschachtelte Funktionsanwendungen in eine Funktionsanwendung zu übersetzen. 
$$f(as..., f(bs...), cs...) \rightarrow f(as..., bs..., cs...)$$
Die Funktion $u \colon T_C \rightharpoonup C$ kann in den Algorithmen dieses Kapitels als Teil der partiellen Interpretation $(u, \mathrm{id})$ gesehen werden. 

\begin{algorithm}
\caption{$\mathrm{flatten} \colon T \times (T_C \rightharpoonup C) \rightarrow T$}\label{flatten}
\begin{algorithmic}[1] %[1] -> jede zeile nummeriert
\Require $t \in T(F, C)$, $u \in (T_C \rightharpoonup C)$
\If {$t = f(t_1, \dots, t_n)$ mit $f$ assoziativ in $u$}
	\While {$t = f(as..., f(bs...), cs...)$}
		\State $t \leftarrow f(as..., bs..., cs...)$
	\EndWhile
\EndIf
\State \textbf{return} $t$ 
\end{algorithmic}
\end{algorithm}

\subsection{Kommutative Funktionsanwendungen}
Eine Normalform für kommutative Funktionsanwendungen erfordert eine totale Ordnung auf der Menge aller Terme $T(F, C)$. Aufbauend auf einer totalen Ordnung von $F$ sowie $C$, kann eine lexikographische Ordnung von $T$ wie folgt definiert werden. 
\begin{itemize}
	\item{sind $c, \tilde{c} \in T$ Konstantensymbole, so ist die Ordnung identisch zu der Ordnung in $C$}
	\item{sind $c, a, \in T$ sowie $c$ ein Konstantensymbol und $a$ eine Funktionsanwendung gilt $c < a$ }
	\item{sind $a = f(ts...), b = g(rs...) \in T$ Funktionsanwendungen und ist $f \neq g$ gilt $a < b \iff f < g $}
	\item{sind $a = f(t_1, \dots, t_n), b = f(r_1, \dots, r_m) \in T$ Funktionsanwendungen, und $\tilde{t_1}, \dots, \tilde{t_n}$, $\tilde{r_1}, \dots, \tilde{r_m}$ die normalisierten Parameter von $a$ und $b$, ist die Ordnung wie folgt}
	\begin{itemize}
		\item{wenn $\exists k \leq \min{(n, m)} \colon \forall i < k ~ \tilde{t_i} = \tilde{r_i} ,~ \tilde{t_k} \neq \tilde{r_k} $ gilt ${a < b \iff \tilde{t_k} < \tilde{r_k}}$}
		\item{ist $n < m$ und $\forall i < n\colon \tilde{t_i} = \tilde{r_i}$ gilt $a < b$}
		\item{ist $n = m$ und $\forall i \leq n\colon \tilde{t_i} = \tilde{r_i}$ gilt $a = b$}
	\end{itemize}
\end{itemize}
Zur Normalisierung einer kommutativen Funktionsanwendung werden zuerst alle Parameter normalisiert, dann können die Parameter nach der lexikographischen Ordnung von $T$ sortiert werden.

\subsection{Teilweise Auswertung}
\begin{algorithm}
\caption{$\mathrm{combine} \colon T \times (T_C \rightharpoonup C) \rightarrow T$}\label{combine}
\begin{algorithmic}[1] %[1] -> jede zeile nummeriert
\Require $t \in T(F, C)$, $u \in (T_C \rightharpoonup C)$
\If {$\mathrm{eval}(u, \mathrm{id})(t) = c \in C$}
	\State \textbf{return} $c$ 
\ElsIf {$t = f(t_1, \dots, t_n)$ mit $f$ assoziativ in $u$}
	\If {$f$ kommutativ in $u$}
		\While {$t = f(xs..., a, ys..., b, zs...) \colon u(f(a, b)) = c \in C$}
			\State $t \leftarrow f(xs..., c, ys..., zs...)$
		\EndWhile
	\Else
		\While {$t = f(xs..., a, b, ys...) \colon u(f(a, b)) = c \in C$}
			\State $t \leftarrow f(xs..., c, ys...)$
		\EndWhile
	\EndIf
	\If {$t = f(t_1)$}
		\State \textbf{return} $t_1$ 
	\EndIf
\EndIf
\State \textbf{return} $t$ 
\end{algorithmic}
\end{algorithm}

Mit der Darstellung assoziativer Funktionen als variadische Funktionen, ist es möglich, dass eine Funktion teilweise ausgewertet werden kann, also gilt für assoziative Funktionssymbole $f \in F$
$$\mathrm{eval}(u, v)(f(a, b)) = c \in C \implies f(xs..., a, b, ys...) = f(xs..., c, ys...)$$
Ist $f$ zudem kommutativ gilt 
$$\mathrm{eval}(u, v)(f(a, b)) = c \in C \implies f(xs..., a, ys..., b, zs...) = f(xs..., c, ys..., zs...)$$
Eine normalisierte Funktionsanwendung ist so weit wie möglich ausgewertet. Sollte sie ganz ausgewertet werden können, ist die normalisierte Funktionsanwendung das Ergebnis der Auswertung. \\
Der Spezialfall ist eine assoziative Funktionsanwendung mit nur einem Parameter. Diese kann immer zu dem Parameter selbst normalisiert werden. 

\subsection{Kombination der einzelnen Vereinfachungen}

\begin{algorithm}
\caption{$\mathrm{normalize} \colon T \times (T_C \rightharpoonup C) \rightarrow T$}\label{normalize}
\begin{algorithmic}[1] %[1] -> jede zeile nummeriert
\Require $t \in T(F, C)$, $u \in (T_C \rightharpoonup C)$
\If {$t = f(t_1, \dots, t_n)$}
	\For {$i \in \{1, \dots, n\}$}
		\State $t_i \leftarrow \mathrm{normalize}(t_i, u)$
	\EndFor
\EndIf
\State $t \leftarrow \mathrm{flatten}(t, u)$
\State $t \leftarrow \mathrm{combine}(t, u)$
\If {$t = f(t_1, \dots, t_n)$ mit $f$ kommutativ in $u$}
	\State sortiere $t_1, \dots, t_n$ lexikographisch
\EndIf
\State \textbf{return} $t$ 
\end{algorithmic}
\end{algorithm}
Algorithmus \ref{normalize} kombiniert die einzelnen Überlegungen dieses Kapitels: Zuerst werden alle Parameter einer Funktionsanwendung normalisiert, dann die Funktionsanwendung selbst.

\section{Patternmatching}
Im vorigen Abschnitt wurde eine erste Normalform für Terme definiert. Alle Vereinfachungen, die dort behandelt wurden, sind recht einfach und direkt zu implementieren, da nur auf lokale Eigenschaften des zu vereinfachenden Terms Rücksicht genommen werden muss. In diesem Abschnitt wird beschrieben, wie ein Term auch zuverlässig auf komplexere Muster geprüft werden kann, so dass nach Implementierung der Mustererkennung selbst viele Vereinfachungsregeln durch jeweils zwei Muster beschrieben werden kann: ein Muster gibt an, welche Struktur im zu vereinfachenden Term gesucht wird, ein zweites Muster gibt an, zu was diese Struktur transformiert wird. Ein Beispiel für ein solches Musterpaar ist etwa die Anwendung der ersten binomischen Formel:
$$a^2 + 2 a b + b^2 \rightarrow (a + b)^2$$
In der etablierten Schreibweise als Term dann geschrieben als:
$$+(\string^(\mathbf a, 2), \cdot(2, \mathbf a, \mathbf b), \string^(\mathbf b, 2)) \rightarrow \string^(+(\mathbf a, \mathbf b), 2)$$
Die Zeichen $\mathbf a$ und $\mathbf b$ stehen dabei nicht für Elemente in $C$, sondern dienen lediglich als Platzhalter für beliebige Teilterme, wobei die verschiedenen Vorkommnisse des selben Zeichens immer auch mit gleichen Termen assoziiert werden müssen. Ein solches Zeichen wird im folgenden \emph{Mustervariable} genannt und zur Unterscheidung fett gedruckt.

\subsection{Muster}
Eine Menge von Termen $T(F, C)$ kann durch Vereinigung von $C$ mit der Menge der Mustervariablen $X$ zu einer Menge von Mustertermen $M$ erweitert werden. 
Um die bisherigen Terme $t \in T$ von Mustertermen zu unterscheiden, werden erstere als \emph{Literal} bezeichnet.
$$M(F, C) \coloneqq T(F, C \cup X)$$
Für ein Paar $(m, t) \in M \times T$ ist eine Funktion $v_m \colon X \rightarrow T$ ein \emph{Match}, wenn folgendes gilt.
$$\mathrm{normalize}(\mathrm{eval}(\mathrm{id}, \tilde v_m)(m))= t$$
$$\tilde v_m(c) = \begin{cases}
	v_m(c) & c \in X\\
	c         & c \in C \setminus X
\end{cases}$$
Jedes Literal ist damit Fixpunkt von $\mathrm{eval}(\mathrm{id}, \tilde v_m)$, wohingegen Mustervariablen auf Nachkommen von $t$ abgebildet werden. 
Klar ist auch, dass ein Match nur für bereits normalisierte Literale $t$ existieren kann, im folgenden werden zudem auch Muster als normalisiert angenommen.\\
Wichtig ist in dem Zusammenhang der Unterschied zwischen der \emph{Musterinterpretation} $(\mathrm{id}, \tilde v_m)$, welche Musterterme als Literale interpretiert und einer Interpretation $(\hat{u}, \hat{v})$ der Literale selbst. Diese zweite Interpretation wird im folgenden als gegeben angenommen. Erneut bezieht sich Kommutativität und Assoziativität von Funktionssymbolen dann auf diese meist implizite Interpretation $(\hat u, \hat v)$.\\

\textbf{Beispiel}\\
Für das Muster $m = +(2, \mathbf a, \mathbf b)$ und das Literal $t = +(2, \sin(x), \cdot(x, y, z))$ ist die Funktion $v_m$ ein Match, wenn $v_m(\mathbf a) = \sin(x)$ und $v_m(\mathbf b) = \cdot(x, y, z)$. Ebenso gültig wäre aber $v_m(\mathbf b) = \sin(x)$ und $v_m(\mathbf a) = \cdot(x, y, z)$, da die Auswertung des Musters $m$ mit der Musterinterpretation noch normalisiert wird, bevor das Ergebnis identisch zu $t$ sein muss.\\

Ein \emph{Matchalgorithmus} ist eine Funktion, die zu einem Paar $(m, t) \in M \times T$ ein Match oder eine Menge von Matches sucht. Mit $\mathcal{P}(A)$ als Potenzmenge der Menge $A$ kann ein Matchalgorithmus damit eine der zwei Formen annehmen.
$$\mathrm{findMatches} \colon M \times T \rightarrow \mathcal{P}(X \rightarrow T)$$
$$\mathrm{findMatch} \colon M \times T \rightarrow X \rightarrow T$$
Es wird sich herausstellen, das die $\mathrm{findMatches}$ genannte Variante elegantere Beschreibungen erlaubt, wohingegen $\mathrm{findMatch}$ in der Laufzeit besser kontrollierbar ist.

\subsection{Erster Matchalgorithmus}

\begin{algorithm}
\caption{$\mathrm{findMatchingPermutation} \colon M \times T \rightarrow \mathcal{P}(X \rightarrow T)$}\label{findMatchingPermutation}
\begin{algorithmic}[1] %[1] -> jede zeile nummeriert
\Require $m \in M$, $t \in T$
\If {$m \in X$}
	\State \textbf{return} $\{v \in (X \rightarrow T) ~|~ v(m) = t\}$ 
\EndIf
\If {$m = f(m_1, \dots, m_n)$ und $t = f(t_1, \dots, t_n)$}
	\If {$f$ kommutativ}
		\State $V \leftarrow \emptyset$
		\ForAll {$(\tilde t_1, \dots, \tilde t_n)$ permutation von $(t_1, \dots, t_n)$}
			\State $V \leftarrow V \cup \bigcap_{i = 1}^n {\mathrm{findMatchingPermutation}(m_i, \tilde t_i)}$
		\EndFor
		\State \textbf{return} $V$
	\Else
		\State \textbf{return} $\bigcap_{i = 1}^n {\mathrm{findMatchingPermutation}(m_i, t_i)}$
	\EndIf
\EndIf
\State \textbf{return} $\emptyset$
\end{algorithmic}
\end{algorithm}

Der erste Matchalgorithmus, dargestellt als Argorithmus \ref{findMatchingPermutation}, findet bereits eine große Teilmenge aller möglichen Matches. Es gibt allerdings zwei schwerwiegende Probleme. Erstens erzeugt Zeile 7 für eine Funktionsanwendung mit $n$ Parametern alle $n!$ Permutationen dieser Parameter, wobei ein Muster sogar mehrere solche Funktionsanwendungen auch mit gegenseitiger Abstammung enthalten kann. Sollte es ein Match geben, ist die Laufzeit damit in $\Omega(n!)$, wobei  $\Omega$ das Landau-Symbol ist, welches die tatsächliche Laufzeit asymptotisch nach unten abschätzt.

Das zweite Problem  ist folgendes: Assoziative Funktionsanwendungen wurden vor der Matchsuche bereits von $\mathrm{combine}$ (Algorithmus \ref{combine}) miteinander verschmolzen, so dass ein Muster mindestens mit der äußersten Funktionsanwendung nicht nur die Terme matchen will, die in ihrer äußersten Funktionsanwendung exakt gleich viele Parameter wie das Muster haben, sondern auch die Funktionsanwendungen mit mehr Parametern (immer vorausgesetzt die einzelnen Parameter des Musters sind matchbar). Für die Lösung dieses zweiten Problems gibt es mehrere Optionen.
Möglich ist, im Matchalgorithmus nicht nur darauf zu achten, ob ein Funktionssymbol kommutativ ist, sondern auch auf Assoziativität entsprechend zu reagieren, also bei der Matchsuche in einer größeren Funktionsanwendung eines assoziativen Funktionssymbols im Literal testweise immer so viele Parameter zu einzelnen Funktionsanwendungen zusammenzufassen, dass die Parameteranzahl von Muster und Literal in der äußersten Funktionsanwendung gleich sind. Ein Muster mit äußerster assoziativer Funktionsanwendung bräuchte dann immer eine Version mit einer weiteren Matchvariable, die beim Matchprozess sonst übrigbleibende Parameter des Literals \glqq aufsagen\grqq{} kann. Das Muster aus Beispiel \textcolor{red}{\textbf{???}} zur Anwendung der ersten binomischen Formel müsste durch eine zweite Version mit einer Mustervariable $\mathbf{c}$ ergänzt werden.
$$+(\string^(\mathbf a, 2), \cdot(2, \mathbf a, \mathbf b), \string^(\mathbf b, 2), \mathbf c) \rightarrow +(\string^(+(\mathbf a, \mathbf b), 2), \mathbf c)$$
Der Vorteil dieser Umsetzung ist die einfachere mathematische Beschreibung, es wurden schließlich keine neuen Konzepte eingeführt, sondern nur der Algorithmus angepasst. Es gibt allerdings auch drei Nachteile. Zum einen muss jede Regel mit äußerer assoziativer Funktionsanwendung auf der linken Seite jetzt mindestens zwei mal vorliegen: Ein mal mit und ein mal ohne extra Variable $\mathbf c$. Für nicht kommutative Funktionen wird die Anzahl sogar noch größer, da auch Parameter nur nicht kommutativ zusammengefasst werden können, also müssen extra Variablen sowohl vor, als auch hinter dem sonstigen Muster ergänzt werden, so dass es dann vier Regeln geben muss, die den selben Sachverhalt beschreiben. 
Ein weiterer Nachteil des Ansatzes besteht darin, dass zwar assoziative Funktionsanwendungen einfach in einem Muster beschrieben werden können, ein Term aber prinzipiell auch nicht assoziative variadische Funktionssymbole enthalten kann. Ein Muster kann also immer nur eine feste Anzahl von Parametern in einer solchen Funktionsanwendung beschreiben, was Muster praktisch nutzlos für die Manipulation solcher Strukturen macht.
Der finale Nagel im Sarg ist die erneut größer gewordene algorithmische Komplexität des Algorithmus. Dem Autor des Musters ist zwar klar, dass die ergänzte Mustervariable nur sonst übrigbleibende Parameter aufsammeln soll, diese Intention geht aber verloren, wenn $\mathbf c$ auch nur eine normale Mustervariable ist. Vor allem die Möglichkeit einer Mustervariable öfter als ein mal vorzukommen wird für die gerade ergänzten Mustervariablen nicht benötigt, da sie sich gerade dadurch auszeichnen, dass die Teile eines Literals, die mit einer solchen Variable gematcht sind für das eigentliche Muster uninteressant sind.
\textcolor{red}{\textit{Frage: Soll der soeben skizzierte erweiterte Algorithmus auch in Pseudocode beschrieben werden?}}

\subsection{Multi-Mustervariablen}
Die in dieser Arbeit gewählte Lösung zur Beschreibung von beliebig vielen Parametern in einem Muster ist im Prinzip schon mit den ersten Definitionen eingeführt worden. Die Schreibweise $f(ts...)$ als kompakte Alternative zu $f(t_1, \dots, t_n)$ hat genau die Eigenschaften, die wir uns nach Analyse von Algorithmus \ref{findMatchingPermutation} gewünscht haben. Eine \textit{Multi-Mustervariable} der Form $\mathbf{ts...}$ kann also nicht nur genau einen Parameter in einer Funktionsanwendung matchen, sondern beliebig viele, auch null. Dafür darf jede Multi-Mustervariable auf der linken Seite einer Ersetzungsregel nur höchstens ein Mal vorkommen. Die rigorose Beschreibung des Konzeptes gestaltet sich allerdings mit der bisher eingeführten Ideen schwierig, da eine Multi-Mustervariable nur Teil einer Funktionsanwendung ist und damit auch alleine keinen vollständigen Term repräsentiert. Konnte eine Matchfunktion $v \colon X \rightarrow T$ vorher einfach auf die Menge aller Terme abbilden, wäre dies nach hinzufügen der Multi-Mustervariablen nicht mehr möglich. Entsprechend umständlicher würde auch die Beschreibung der Auswertung eines Musters werden. \\

Formal wird die Multi-Mustervariable damit nicht als echtes neues Symbol in die Menge der Muster aufgenommen, sondern ist lediglich eine vereinfachende Schreibweise, die wie auch vorher immer für eine beliebige Anzahl an Teiltermen steht, in diesem Fall Mustervariablen. Ein Muster mit einer Multi-Mustervariable $\mathbf{ts...}$ repräsentiert also formal unendlich viele konkrete Muster mit konkreten Mustervariablen $\mathbf{t_i}$:
\begin{equation*}
    \begin{split}
    		f(\mathbf{ts...}) = \{&f(), \\
    		&f(\mathbf{t_1}),\\
    		&f(\mathbf{t_1}, \mathbf{t_2}), \\
    		&f(\mathbf{t_1}, \mathbf{t_2}, \mathbf{t_3}), \\
    		&\dots \}    		
    \end{split}
\end{equation*}
Für die folgenden Algorithmen und auch in der echten Umsetzung ist es allerdings nicht praktikabel diese Definition anzuwenden, Multi-Mustervariablen werden also formal inkorrekt als einzelne Symbole in einem tatsächlichen Muster betrachtet.

Die Anwendung der ersten binomischen Formel kann jetzt in einer einzigen Regel beschrieben werden.
$$+(\string^(\mathbf a, 2), \cdot(2, \mathbf a, \mathbf b), \string^(\mathbf b, 2), \mathbf{cs...}) \rightarrow +(\string^(+(\mathbf a, \mathbf b), 2), \mathbf{cs...})$$

\section{Termersetzungssystem}
\textcolor{red}{
\begin{itshape}
Anmerkung: Dieses Kapitel wird recht kurz und ist auch als Unterkapitel von Patternmatching denkbar. 
Während in Patternmatching (bisher) immer nur mit einem Muster und dem Gesamtterm gematcht wird, Werden hier mehrere Muster auf jeden Teilterm angewendet, bis keine Anwendung mehr möglich ist
\end{itshape}
}

\section{Umsetzung in C\texttt{++}}
\textcolor{red}{
\begin{itshape}
Anmerkung: Hier wird erläutert, wie meine konkrete Implementierung Terme speichert und verwaltet und wie die Algorithmen konkret umgesetzt sind. Vielleicht auch noch wo anders im Text anzufinden, aber auch jeden Fall auch hier ist meine Implementierung der Lambdafunktion als Term, was die Vereinfachungsmuster noch etwas ausdrucksstärker macht. Dann gibt es noch spezielle Matchvariablen, die darauf optimiert sind bestimmte Werte zu matchen, die werde ich an dieser Stelle auch erläutern, mathematisch rigoros ist mir das glaube ich zu aufwendig.
Mögliche Tangenten:
\begin{itemize}
\item {Ausflug in die Codegenerierung mit Templates für Funktionen, die genau ein Muster matchen (ist ein recht tiefes Kaninchenloch)}
\item {Meine Idee (und Umsetzung) einer Art Aufzählung (in cpp und Co. als enum in der Sprache enthalten), die Hierarchien erlaubt und damit Basis eines (wie ich finde) relativ eleganten Typsystems für die einzelnen Arten von Termknoten darstellt}
\item {Idee und Umsetzung eines sehr einfachen Typsystems}
\item{Möglichkeit Mustervariablen nur zu matchen, sollten Extrabedingungen erfüllt sein}
\item {Speichermanagement}
\end{itemize}
\end{itshape}
}


\section{Vereinfachen von arithmetischen Termen}
\begin{itshape}
\textcolor{red} {Anmerkung zur Anmerkung: ab hier sind es nur noch Anmerkungen, da wird Farbe gespart (in echt mag \LaTeX{}  es nicht über Kapitelgrenzen hinweg zu färben).}
Anmerkung: Ich habe begonnen das Termersetzungssystem zu entwickeln, um Arithmetische Ausdrücke zu vereinfachen (etwa $a + 2 a \rightarrow 3 a$). Wie genau ich das umsetze, wird in diesem Abschnitt erläutert.
\\Während die Datenstruktur und der Matchingalgorithmus schon benutzbar sind, ist dieser Teil von mir bisher so gut wie gar nicht implementiert worden. Der grobe Plan ist aber folgender:
\begin{enumerate}
    \item Funktionen höherer Ordnung anwenden:
    \begin{itemize}
        \item ableiten (Prototyp dafür steht schon)
        \item vielleicht integrieren (soll für den allgemeinen Fall wohl schwer sein)
        \item vielleicht fouriertransformieren
        \item vielleicht laplacetransformieren
        \item ganz ganz ganz ganz vielleicht Differentialgleichungen lösen
    \end{itemize}
    \item Normalform herstellen:
    \begin{itemize}
        \item alles ausmultiplizieren ($a\cdot (b + c) \rightarrow a\cdot b + a\cdot c$)
        \item Vorzeichen aus ungeraden Funktionen herausziehen ($\sin(-x) \rightarrow -\sin(x)$)
        \item Vorzeichen in geraden Funktionen auf plus setzen ($\cos(-x) \rightarrow \cos(x)$)
        \item Überlegen, wie man das selbe für Fälle mit Summen im Argument definiert ($\cos(a - b)$ vs. $\cos(b - a)$)
        \item bekannte Faktoren aus Potenz ziehen ($(3 x)^2 \rightarrow 9 x^2$)
        \item \dots
    \end{itemize}
    \item Vereinfachen:
    \begin{itemize}
        \item manche Transformationen sollten immer angewendet werden (etwa $\sin^2(x) + \cos^2(x) \rightarrow 1)$
        \item andere Transformationen nur ausprobieren und mit einer passenden Metrik gucken, wie gut ein Term nach Anwendung noch weiter vereinfacht werden kann (etwa, wenn man aus verschiedenen Optionen des Ausklammerns wählen kann)
        \item vielleicht Linearfaktorzerlegung von Polynomen (schätze ich für den allgemeinen Fall schwierig ein, solange ich nur exakte Operationen zulasse)
        \item vielleicht Polynomdivision (schätze ich genau so schwierig ein, zumindest wenn ich nicht vorher schon Linearfaktoren habe)
        \item \dots
    \end{itemize}
\end{enumerate}
~\\~
Anmerkung 1: Die Normalform ist notwendig, um zu garantieren, dass mehrfaches Auftreten eines Teilbaums / Teilterms auch erkannt wird. \\
Anmerkung 2: es kann sein, dass ich manche Eigenschaften der Normalformauch während des Vereinfachungsschrittes immer wieder wiederherstellen muss.

\subsection{Vergleich meiner Features mit anderen Computeralgebrasystemen}
Ich bin ja nicht der erste, der auf die Idee kommt, Terme zusammenzufassen. Wolphram Alpha und Maple sind zwar nicht Open Source, aber andere Optionen, wie etwa SymPy aus der Python Standardbibliothek soweit ich weiß schon. Da lässt sich bestimmt ein bisschen vergleichen, wie andere Leute die selben Probleme lösen.
\end{itshape}

\section{Zusammenfassung}
\begin{itshape}
Was halt in eine Zusammenfassung kommt
\end{itshape}


\printbibliography

\end{document}
