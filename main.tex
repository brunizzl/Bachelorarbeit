
\documentclass{scrartcl}
\usepackage[utf8]{inputenc}

\title{Entwicklung eines Termersetzungssystems für assoziative und kommutative Ausdrücke zum vereinfachen arithmetischer Terme\\ \textit{Version 0.0.2}}
\author{Bruno Borchardt}
\date{\today}

\usepackage{csquotes}
\usepackage[ngerman]{babel}

\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsmath} %  \begin{cases}  Wert 1 & Bedingung 1 \\ Wert 2 & Bedingung 2 \\ \end{cases} 
\numberwithin{figure}{section} %label nr. beinhaltet section

\usepackage{qtree}
\usepackage{algorithm}
\usepackage{algpseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\usepackage[backend=biber, style=alphabetic]{biblatex}
\addbibresource{quellen.bib}
%\bibliographystyle{plain}
%\bibliography{references}

\usepackage{xcolor} %\textcolor{blue}{This is a sample text in blue.}

\usepackage{minted}
\renewcommand{\listingscaption}{Quelltext}
\usemintedstyle{friendly}

%\paren*{a + b} skaliert automatisch klammern um a + b
\DeclarePairedDelimiter\paren{(}{)} 
\DeclarePairedDelimiter\curl{\{}{\}}

\setlength{\parindent}{0pt} %keine Einrückung nach absatz

\usepackage{amsthm}
\theoremstyle{definition} %keine kursiven theoreme

%.........................................................................
%................................ Macros .................................
%.........................................................................

% baut teile eines tupels: "t_1, ..., t_n"
\newcommand{\elems}[3]{{#1}_{#2}, \dots, {#1}_{#3}}
\newcommand{\tOneN}{\elems t 1 n}

% stapelt zweiten parameter auf ersten
\newcommand{\stapel}[2]{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily {#2}}}}{#1}}}

%.........................................................................
%................................ Body ...................................
%.........................................................................
\begin{document}

\maketitle

\tableofcontents

\clearpage
%\cleardoublepage <- für andere Dokumenttypen

\section{Einleitung} \label{secEinleitung}
\textcolor{red} {
\begin{itshape}
Anmerkung: Hier kommt hin, was halt in eine Einleitung soll:
\begin{itemize}
    \item was ist ein Termersetzungssystem?
    \item Einsatz von Termersetzungssystemen
    \begin{itemize}
        \item Beweisprüfer /Beweisassistenten
        \item Arithmetikausdrücke vereinfachen
        \item Optimierender Compiler
	\item Interpreter funktionaler Sprachen
        \item bestimmt noch mehr
    \end{itemize}
    \item was soll die in dieser Arbeit umgesetzte Variante (gut) können?
\end{itemize}
\end{itshape}
}

Die Idee Computer zu nutzen um symbolische Ausdrücke zu manipulieren ist fast so alt wie der Computer selbst.  LISP \cite{lisp} ist als eine der ersten höheren Programmiersprachen bereits für diesen Zweck geschaffen worden. 

\subsection{Zielsetzung}
Diese Arbeit hat zwei Ziele. Finales Ergebnis ist ein Computeralgebrasystem, also ein Programm, welches mathematische Ausdrücke vereinfachen kann, auch, wenn der numerische Wert des Ausdruckes nicht bekannt ist. Als Zwischenschritt wird eine Methode entwickelt, um kompakt formulierte Ersetzungsregeln auf solche Ausdrücke anwenden zu können. Eine Ersetzungsregel besteht dabei immer aus einer linken Seite und einer rechten Seite. Ziel ist es, das Muster der linken Seite im zu vereinfachenden Ausdruck zu finden und durch die rechte Seite zu ersetzen. Das finale Computeralgebrasystem soll hauptsächlich verschiedene Mengen von Vereinfachungsregeln in einer geschickt gewählten Reihenfolge anwenden. Die Vereinfachungsregeln sind damit so zu wählen, das der vereinfachte Ausdruck äquivalent zum Ursprungsausdruck ist.


\newtheorem{bsp}{Beispiel}[section]
\begin{bsp}~\\
Neben dem Auswerten von Ausdrücken ohne Unbekannte zu reellen Zahlen, werden vier Vereinfachungsregeln definiert:
\begin{alignat*}{4}
    ~& a \cdot b + a \cdot c & &= a \cdot (b + c) &~~~& (1) \\
    ~& \sqrt{a}              & &= a^{\frac 1 2}   &~~~& (2) \\
    ~& \paren{a^b}^c         & &= a^{b \cdot c}   &~~~& (3) \\
    ~& \sin(a)^2 + \cos(a)^2 & &= 1               &~~~& (4)
\end{alignat*}
Der folgende Ausdruck kann so zur Zahl $3$ vereinfacht werden.
\begin{equation*}
    \begin{split}
	3 \cdot \sin(x + y)^2 + 3 \cdot \sqrt{\cos(x + y)^4} 
	&\stapel = {(1)} 3 \cdot \paren*{\sin(x + y)^2 + \sqrt{\cos(x + y)^4}} \\
	&\stapel = {(2)} 3 \cdot \paren*{\sin(x + y)^2 + \paren*{{\cos(x + y)^4}}^{\frac 1 2}}\\
	&\stapel = {(3)} 3 \cdot \paren*{\sin(x + y)^2 + {\cos(x + y)^2}}\\
	&\stapel = {(4)} 3
    \end{split}
\end{equation*}
Hervorzuheben ist dabei, dass Variablennamen wie $a$ oder $b$ in den Vereinfachungsregeln eine andere Bedeutung haben, als die Variablen $x$ und $y$ im zu vereinfachenden Ausdruck. Erstere sind Platzhalter in der Ersetzungsregel, stehen damit also representativ für einen Teil des Ausdrucks, der transformiert wird, während zweitere nur eine Bedeutung außerhalb des Ersetzungssystems haben. Formalisiert wird dieser Unterschied in Abschnitt \ref{subsecMuster}. Als Beispiel wird das Variablensymbol $b$ der Ersetzungsregel $(1)$ in der Anwendung der Regel mit den Ausdruck $\sin(x + y)^2$ assoziiert. 
\end{bsp}

\section{Grundlegende Definitionen} \label{secGrundlegendeDefinitionen}

\subsection{Term}
Eine Menge von Termen $T$ ist in dieser Arbeit immer  in Abhängigkeit der Mengen $F$ und $C$, sowie der \emph{Stelligkeitsfunktion} $\mathrm{arity} \colon F \rightarrow \mathbb{N} \cup \{\omega\}$ definiert. $F$ enthält die sogenannten \emph{Funktionssymbole}. Beispiele für mögliche Elemente in $F$ sind \texttt{sin} und \texttt{sqrt}, zudem auch Operatoren wie die Division, etwa geschrieben als \texttt{divide}. Die Stelligkeitsfunktion gibt für jedes Funktionssymbol an, wie viele Parameter erwartet werden. Eine mögliche Stelligkeit der genannten Beispielsymbole ist die folgende.

$$\mathrm{arity} f = \begin{cases}
2 & f  = \texttt{divide}\\
1 & f \in \{\texttt{sin}, \texttt{sqrt}\}\\
\end{cases}$$

Kann eine Funktionssymbol $f$ beliebig viele Parameter entgegennehmen, wird gesagt, dass $f$ \emph{variadische} Stelligkeit hat oder \emph{variadisch} ist. Die Stelligkeitsfunktion bildet $f$ dann auf $\omega$ ab. 

Die Menge $C$ enthält die \emph{Konstantensymbole}. Mit den genannten Beispielen für Funktionssymbole, ergibt etwa $C = \mathbb R$ Sinn. Wichtig ist allerdings, dass im folgenden nicht vorausgesetzt wird, dass jedem Konstantensymbol ein eindeutiger Wert zugeordnet werden kann\footnote{Die Symbole unbekannten Wertes werden häufig von den Konstantensymbolen getrennt und Variablensymbole genannt. Diese Unterscheidung wird hier nicht getroffen, vor allem um die später eingeführten Mustervariablen besser von Konstantensymbolen abzugrenzen.}.



Ein Term $t \in T(F, C)$ ist dann  {
\begin{itemize}
	\item{ein Konstantensymbol, also $t \in C$}
	\item{oder eine \emph{Funktionsanwendung} des Funktionssymbols $f \in F$ mit $\mathrm{arity} f \in \{n, \omega\}$ 
		auf die Terme ${\tOneN \in T(F, C)}$, geschrieben ${t = (f, \tOneN)}$}
\end{itemize}}
In Mengenschreibweise:
$$T(F, C) \coloneqq C \cup \curl*{
(f, \tOneN)~|
~f\in F,~\mathrm{arity}(f) \in \{n, \omega\},~ \tOneN \in T(F, C)
}$$ 
Eine Funktionsanwendung wird in der Literatur oft mit dem Funktionssymbol außerhalb des Tupels geschrieben \cite{buch1977}, also $f(\tOneN)$ statt $(f, \tOneN)$. Zum deutlicheren Abheben von Funktionen die Terme transformieren zu Termen selbst, wird diese Schreibweise hier keine Verwendung finden. 


\begin{figure}
\Tree [.\texttt{divide} 3 [.\texttt{sin} 1 ] ]
\label{ersterBeispielBaum}
\caption{Baumdarstellung des Terms $(\texttt{divide}, 3, (\texttt{sin}, 1))$ }
\end{figure}

\newtheorem{bBaum}[bsp]{Beispiel}
\begin{bBaum}~\\
Als Beispiel lässt sich der Ausdruck $\frac 3 {\sin 1}$ in der formalen Schreibweise als Term mittels der Funktionssymbole $\texttt{sin}$ und $\texttt{divide}$, sowie den Konstantensymbolen $3$ und $1$ darstellen als $(\texttt{divide}, 3, (\texttt{sin}, 1))$. Ein Term kann dabei auch immer als Baum\footnote{In der theoretischen Informatik auch Syntaxbaum oder AST (englisch für \textit{Abstract Syntax Tree})} aufgefasst werden, etwa das aktuelle Beispiel in in Abb. \ref{ersterBeispielBaum} .
\end{bBaum}

Mit dem Kontext der Baumdarstellung lassen sich nun die folgenden Begriffe auf Terme übertragen. In der Funktionsanwendung $t = (f, \tOneN)$ sind $\tOneN$ die \emph{Kinder} ihres \emph{Vaters} $t$. Kinder sind allgemeiner \emph{Nachkommen}. Nachkommen verhalten sich transitiv, also ein Nachkomme $z$ des Nachkommen $y$ von $x$ ist auch ein Nachkomme von $x$. Umgekehrt ist $x$ \emph{Ahne} von $y$ und $z$. \\


\subsection{Funktionsauswertung}
Die Erweiterung des Funktionssymbols zur Funktion, die von einem Raum $Y^n$ nach $Y$ abbildet, folgt mittels der $\mathrm{eval}$ Funktion frei nach \cite{buch1977}.

\begin{equation*}
    \begin{split}
	\mathrm{eval} &\colon \paren*{F \rightarrow \bigcup_{n \in \mathbb{N}} Y^n \rightarrow Y} \times (C \rightarrow Y) \rightarrow T \rightarrow Y\\
	\mathrm{eval} &(u, v)~t = \begin{cases}
		u~f~(\elems {\mathrm{eval}(u, v)~t} 1 n) & t = (f, \tOneN)\\
		v~t                                      & t \in C\\
		\end{cases}
    \end{split}
\end{equation*}
Gilt $\mathrm{arity} f = n \in N$ für ein $f \in F$, ist zudem die Funktion $u~f \colon Y^n \rightarrow Y$ in ihrer Definitionsmenge auf Dimension $n$ eingeschränkt. 
Die Funktion $u$ wird als \emph{Interpretation} der Funktionssymbole $F$, die Funktion $v$ als Interpretation der Konstantensymbole $C$ und das Paar $(u, v)$ als Interpretation der Terme $T(F, C)$ bezeichnet. Die Funktion $\mathrm{eval}(u, v) \colon T \rightarrow Y$ ist eine \emph{Auswertung} nach $Y$. 
\\~\\

\newtheorem{bEval}[bsp]{Beispiel}
\begin{bEval}~\\
Sei $F = \{\texttt{sum}, \texttt{prod}, \texttt{neg} \}$ und $C = \mathbb{N}$ mit $\mathrm{arity}~ \texttt{sum} = \mathrm{arity}~ \texttt{prod} = \omega$ und $\mathrm{arity}~ \texttt{neg} = 1$.
Die Interpretation $(u, v)$ kann so gewählt werden, dass jeder Term in $T$ zu einer ganzen Zahl auswertbar ist.

\begin{equation*}
    \begin{split}
    u~\texttt{sum}  ~(\elems y 1 n) &= \Sigma_{k = 1}^n y_k\\
    u~\texttt{prod} ~(\elems y 1 n) &=    \Pi_{k = 1}^n y_k\\
    u~\texttt{neg}~y &= -y\\
    &\\
    v~y &= y
    \end{split}
\end{equation*}

Hervorzuheben ist dabei, dass $u~\texttt{neg} \colon \mathbb Z \rightarrow \mathbb Z$ nur eine Ganze Zahl als Parameter erwartet, während $u~\texttt{sum}$ und $u~\texttt{prod}$ Tupel Ganzer Zahlen beliebiger Länge abbilden können.
Der Term $t = (\texttt{sum}, 3, (\texttt{prod}, 2, 4), (\texttt{neg}, 1))$ kann dann ausgewertet werden zu 
\begin{equation*}
    \begin{split}
    \mathrm{eval}(u, v)~t &= \mathrm{eval}(u, v) (\texttt{sum}, 3, (\texttt{prod}, 2, 4), (\texttt{neg}, 1)) \\
    &= u~\texttt{sum}~(\mathrm{eval}(u, v)~3, \mathrm{eval}(u, v)(\texttt{prod}, 2, 4),  \mathrm{eval}(u, v) (\texttt{neg}, 1)) \\
    &= u~\texttt{sum}~(v~3, u~\texttt{prod}~(\mathrm{eval}(u, v)~2, \mathrm{eval}(u, v)~4), u~\texttt{neg}~ 1) \\
    &= u~\texttt{sum}~(3, u~\texttt{prod}~(v~2, v~4), -1) \\
    &= u~\texttt{sum}~(3, u~\texttt{prod}~(2, 4), -1) \\
    &= u~\texttt{sum}~( 3, 8, -1) \\
    &= 10 \\
    \end{split}
\end{equation*}
\end{bEval}

\newtheorem{defKonstruktor}[bsp]{Definition}
\begin{defKonstruktor}~\\
Eine direkt aus der Struktur des Terms folgende Interpretation $u_c$ für Funktionssymbole ist die des \emph{Konstruktors}. Als Konstruktor eines Typen $A$ wird eine Funktion bezeichnet, die nach $A$ abbildet \cite{haskellConstructor}. Mit $f \in F$ und $\mathrm{arity} f = n \in \mathbb N$ 
gilt $$u_c~f \colon T^n \rightarrow T, ~(\tOneN) \mapsto (f, \tOneN)$$
Mit einem beliebigen $v \colon C \rightarrow C'$ ändert die Auswertung $\mathrm{eval}(u_c, v) \colon T(F, C) \rightarrow T(F, C')$ damit nur die Konstantensymbole eines Terms, lässt aber die sonstige Struktur unverändert. Insbesondere ist $\mathrm{eval}(u_c, v) \colon T \rightarrow T$ mit $v~y = y$ die Identität.

Die Interpretation $u_c$ reicht für bestimmte Funktionssymbole aus, etwa kann so das Funktionssymbol $\texttt{pair}$ ein Paar als Term darstellen.
$$u_c~\texttt{pair} \colon T^2 \rightarrow T, ~(a, b) \mapsto (\texttt{pair}, a, b)$$
Äquivalent ist die Darstellung endlicher Mengen und Vektoren mit variadischen Funktionssymbolen \texttt{set} und \texttt{vec} möglich.
\end{defKonstruktor}


\subsection{Muster} \label{subsecMuster}

Bisher wurden die Objekte beschrieben, die in dieser Arbeit transformiert werden sollen. Die Transformationsregeln selbst lassen sich allerdings auch als Paare von bestimmten Termen darstellen. Zur Abgrenzung beider Konzepte werden die zu transformierenden Terme $t\in T(F, C)$ von hier an \emph{Literal} genannt, Terme die  Teil einer Regeldefinition sind werden \emph{Muster} genannt. Die Menge der Muster $M(F, C)$ ist dabei eine Obermenge der Literale, da sie deren Konstantensymbole um die Menge der \emph{Mustervariablen} $X$ erweitert. Konkrete Elemente $\mathbf x \in X$ werden im folgenden $\mathbf{fett}$ geschrieben.
$$M(F, C) \coloneqq T(F, C \cup X)$$

Eine \emph{Umformungsregel} für Literale $t \in T(F, C)$ hat also die Form $(l, r) \in M(F, C)^2$. Die linke Seite $l$ steht für das Muster, dass im Literal durch einen Ausdruck der Form der rechten Seite $r$ ersetzt werden soll. Für die bessere Lesbarkeit wird statt $(l, r)$ auch $l = r$ geschrieben.

\newtheorem{bMuster}[bsp]{Beispiel}
\begin{bMuster}
Die Regel, die die Summe zweier identischer Terme $a$ als Produkt von $2$ und $a$ transformiert wird geschrieben als
$$(\texttt{sum}, \textbf a, \textbf a) = (\texttt{prod}, 2, \textbf a)$$
Wird die Regel jetzt auf das Literal 
$t = (\texttt{sum}, (\texttt{sin}, 3), (\texttt{sin}, 3))$ angewandt, kann man $t$ zu $t' = (\texttt{prod}, 2, (\texttt{sin}, 3))$ transformieren.
\end{bMuster}



\section {Erste Normalform} \label{secErsteNormalform}

Das Kernthema dieser Arbeit ist die Vereinfachung von Termen. Eine Vereinfachung ist allerdings nur gültig, sofern sich die Bedeutung des vereinfachten Terms gegenüber der des ursprünglichen Terms nicht geändert hat. Da ein Term in sich keine Bedeutung trägt, muss eine Vereinfachung immer in Bezug auf eine Interpretation gesehen werden. Etwa kann der Ausdruck $X A X^{-1}$ zu $A$ vereinfacht werden, wenn $X, A \in \mathbb{C} \setminus \{0\}$, allerdings ist die Vereinfachung allgemein nicht möglich, sollten die Symbole $X$ und $A$ für Matritzen stehen. \\
Im folgenden wird von der Assoziativität oder Kommutativität bestimmter Funktionssymbole gesprochen. Diese ist immer im Kontext einer entsprechenden Interpretation zu sehen. Gleichzeitig ist aber auch klar, dass unabhängig von der Interpretation verschiedene Funktionssymbole die Rolle der Multiplikation übernehmen müssen, sollte sowohl skalare Multiplikation als auch Matrixmultiplikation im selben Term möglich sein. \\

In diesem Abschnitt werden erste Termumformungen beschrieben, die isolierte Eingenschaften einzelner Funktionen ausnutzen. Ziel ist es kommutative und assoziative Funktionsanwendungen eindeutig darzustellen.\\

Häufig werden Abschnitte der Parameter einer Funktionsanwendung beliebiger Länge der Form $\elems t i k$ vorkommen. Kompakt wird $ts...$ für den (möglicherweise leeren) Abschnitt des Funktionsanwendungstupels geschrieben. Das $s$ in $ts...$ ist dann nicht als einzelnes Symbol zu lesen, sondern als Suffix um $t$ in den Plural zu setzen. \\$f(\elems t 1 k, a, \elems t {k+2} n)$ kann also äquivalent $f(ts..., a, rs...)$ geschrieben werden, mit $(\elems t 1 k) = (ts...)$ und $(\elems t {k+2} n) = (rs...)$.\\

\subsection {Assoziative Funktionsanwendungen}
Die geschachtelte Anwendung einer assoziativen Funktion führt je nach Klammersetzung zu verschiedenen mathematisch equivalenten Termen. Als Beispiel dient hier die Addition, dargestellt als Anwendung des Funktionssymbols $+$. Die folgenden Ausdrücke sind paarweise verschiedene Terme, jedoch alle mathematisch äquivalent.
\begin{equation*}
	\begin{split}
	+(+(+(a, b), c), d) &= +(+(a, +(b, c)), d)\\
	&= +(+(a, b), +(c, d))\\
	&= +(a, +(b, +(c, d)))\\
	&= \dots \\
	\end{split}
\end{equation*}
Es gibt mehrere Optionen eine solche Schachtelung in einem Term zu normalisieren, also in eine eindeutige Form zu bringen. Die erste ist, festzulegen, dass höchstens einer der beiden Parameter der binären assoziativen Funktion wieder Ergebnis dieser Funktion sein darf. Wählt man den zweiten Parameter dafür aus, wird die Summe in der Normalform dargestellt als $+(a, +(b, +(c, d)))$. Diese Methode nennt sich Pivotisierung und wird in \textcolor{red}{\textbf{Quellen}} näher untersucht.\\
Alternativ kann man die Summe von zwei Parametern auch als Spezialfall einer Summe von $n \in \mathbb{N}$ Parametern auffassen, dann gewohnt geschrieben als $\Sigma_{x \in \{a, b, c, d\}} x$. Dieser Weg wird im folgenden gewählt, wobei die Darstellung als Term dann $+(a, b, c, d)$ ist. Assoziative Funktionen sind in der gewählten Darstellung damit variadisch. \\
Die Normalisierung von Funktionsanwendungen des assoziativen Funktionssymbols $f$ bedeutet dann geschachtelte Funktionsanwendungen in eine Funktionsanwendung zu übersetzen. 
$$f(as..., f(bs...), cs...) \rightarrow f(as..., bs..., cs...)$$
Die Funktion $u \colon T_C \rightharpoonup C$ kann in den Algorithmen dieses Kapitels als Teil der partiellen Interpretation $(u, \mathrm{id})$ gesehen werden. 

\begin{algorithm}
\caption{$\mathrm{flatten} \colon T \times (T_C \rightharpoonup C) \rightarrow T$}\label{flatten}
\begin{algorithmic}[1] %[1] -> jede zeile nummeriert
\Require $t \in T(F, C)$, $u \in (T_C \rightharpoonup C)$
\If {$t = f(t_1, \dots, t_n)$ mit $f$ assoziativ in $u$}
	\While {$t = f(as..., f(bs...), cs...)$}
		\State $t \leftarrow f(as..., bs..., cs...)$
	\EndWhile
\EndIf
\State \textbf{return} $t$ 
\end{algorithmic}
\end{algorithm}

\subsection{Kommutative Funktionsanwendungen}
Eine Normalform für kommutative Funktionsanwendungen erfordert eine totale Ordnung auf der Menge aller Terme $T(F, C)$. Aufbauend auf einer totalen Ordnung von $F$ sowie $C$, kann eine lexikographische Ordnung von $T$ wie folgt definiert werden. 
\begin{itemize}
	\item{sind $c, \tilde{c} \in T$ Konstantensymbole, so ist die Ordnung identisch zu der Ordnung in $C$}
	\item{sind $c, a, \in T$ sowie $c$ ein Konstantensymbol und $a$ eine Funktionsanwendung gilt $c < a$ }
	\item{sind $a = f(ts...), b = g(rs...) \in T$ Funktionsanwendungen und ist $f \neq g$ gilt $a < b \iff f < g $}
	\item{sind $a = f(t_1, \dots, t_n), b = f(r_1, \dots, r_m) \in T$ Funktionsanwendungen, und $\tilde{t_1}, \dots, \tilde{t_n}$, $\tilde{r_1}, \dots, \tilde{r_m}$ die normalisierten Parameter von $a$ und $b$, ist die Ordnung wie folgt}
	\begin{itemize}
		\item{wenn $\exists k \leq \min{(n, m)} \colon \forall i < k ~ \tilde{t_i} = \tilde{r_i} ,~ \tilde{t_k} \neq \tilde{r_k} $ gilt ${a < b \iff \tilde{t_k} < \tilde{r_k}}$}
		\item{ist $n < m$ und $\forall i < n\colon \tilde{t_i} = \tilde{r_i}$ gilt $a < b$}
		\item{ist $n = m$ und $\forall i \leq n\colon \tilde{t_i} = \tilde{r_i}$ gilt $a = b$}
	\end{itemize}
\end{itemize}
Zur Normalisierung einer kommutativen Funktionsanwendung werden zuerst alle Parameter normalisiert, dann können die Parameter nach der lexikographischen Ordnung von $T$ sortiert werden.

\subsection{Teilweise Auswertung}
\begin{algorithm}
\caption{$\mathrm{combine} \colon T \times (T_C \rightharpoonup C) \rightarrow T$}\label{combine}
\begin{algorithmic}[1] %[1] -> jede zeile nummeriert
\Require $t \in T(F, C)$, $u \in (T_C \rightharpoonup C)$
\If {$\mathrm{eval}(u, \mathrm{id})(t) = c \in C$}
	\State \textbf{return} $c$ 
\ElsIf {$t = f(t_1, \dots, t_n)$ mit $f$ assoziativ in $u$}
	\If {$f$ kommutativ in $u$}
		\While {$t = f(xs..., a, ys..., b, zs...) \colon u(f(a, b)) = c \in C$}
			\State $t \leftarrow f(xs..., c, ys..., zs...)$
		\EndWhile
	\Else
		\While {$t = f(xs..., a, b, ys...) \colon u(f(a, b)) = c \in C$}
			\State $t \leftarrow f(xs..., c, ys...)$
		\EndWhile
	\EndIf
	\If {$t = f(t_1)$}
		\State \textbf{return} $t_1$ 
	\EndIf
\EndIf
\State \textbf{return} $t$ 
\end{algorithmic}
\end{algorithm}

Mit der Darstellung assoziativer Funktionen als variadische Funktionen, ist es möglich, dass eine Funktion teilweise ausgewertet werden kann, also gilt für assoziative Funktionssymbole $f \in F$
$$\mathrm{eval}(u, v)(f(a, b)) = c \in C \implies f(xs..., a, b, ys...) = f(xs..., c, ys...)$$
Ist $f$ zudem kommutativ gilt 
$$\mathrm{eval}(u, v)(f(a, b)) = c \in C \implies f(xs..., a, ys..., b, zs...) = f(xs..., c, ys..., zs...)$$
Eine normalisierte Funktionsanwendung ist so weit wie möglich ausgewertet. Sollte sie ganz ausgewertet werden können, ist die normalisierte Funktionsanwendung das Ergebnis der Auswertung. \\
Der Spezialfall ist eine assoziative Funktionsanwendung mit nur einem Parameter. Diese kann immer zu dem Parameter selbst normalisiert werden. 

\subsection{Kombination der einzelnen Vereinfachungen}

\begin{algorithm}
\caption{$\mathrm{normalize} \colon T \times (T_C \rightharpoonup C) \rightarrow T$}\label{normalize}
\begin{algorithmic}[1] %[1] -> jede zeile nummeriert
\Require $t \in T(F, C)$, $u \in (T_C \rightharpoonup C)$
\If {$t = f(t_1, \dots, t_n)$}
	\For {$i \in \{1, \dots, n\}$}
		\State $t_i \leftarrow \mathrm{normalize}(t_i, u)$
	\EndFor
\EndIf
\State $t \leftarrow \mathrm{flatten}(t, u)$
\State $t \leftarrow \mathrm{combine}(t, u)$
\If {$t = f(t_1, \dots, t_n)$ mit $f$ kommutativ in $u$}
	\State sortiere $t_1, \dots, t_n$ lexikographisch
\EndIf
\State \textbf{return} $t$ 
\end{algorithmic}
\end{algorithm}
Algorithmus \ref{normalize} kombiniert die einzelnen Überlegungen dieses Kapitels: Zuerst werden alle Parameter einer Funktionsanwendung normalisiert, dann die Funktionsanwendung selbst.

\section{Patternmatching} \label{secPattermatching}
Im vorigen Abschnitt wurde eine erste Normalform für Terme definiert. Alle Vereinfachungen, die dort behandelt wurden, sind recht einfach und direkt zu implementieren, da nur auf lokale Eigenschaften des zu vereinfachenden Terms Rücksicht genommen werden muss. In diesem Abschnitt wird beschrieben, wie ein Term auch zuverlässig auf komplexere Muster geprüft werden kann, so dass nach Implementierung der Mustererkennung selbst viele Vereinfachungsregeln durch jeweils zwei Muster beschrieben werden kann: ein Muster gibt an, welche Struktur im zu vereinfachenden Term gesucht wird, ein zweites Muster gibt an, zu was diese Struktur transformiert wird. Ein Beispiel für ein solches Musterpaar ist etwa die Anwendung der ersten binomischen Formel:
$$a^2 + 2 a b + b^2 \rightarrow (a + b)^2$$
In der etablierten Schreibweise als Term dann geschrieben als:
$$+(\string^(\mathbf a, 2), \cdot(2, \mathbf a, \mathbf b), \string^(\mathbf b, 2)) \rightarrow \string^(+(\mathbf a, \mathbf b), 2)$$
Die Zeichen $\mathbf a$ und $\mathbf b$ stehen dabei nicht für Elemente in $C$, sondern dienen lediglich als Platzhalter für beliebige Teilterme, wobei die verschiedenen Vorkommnisse des selben Zeichens immer auch mit gleichen Termen assoziiert werden müssen. Ein solches Zeichen wird im folgenden \emph{Mustervariable} genannt und zur Unterscheidung fett gedruckt.

\subsection{Muster}
Eine Menge von Termen $T(F, C)$ kann durch Vereinigung von $C$ mit der Menge der Mustervariablen $X$ zu einer Menge von Mustertermen $M$ erweitert werden. 
Um die bisherigen Terme $t \in T$ von Mustertermen zu unterscheiden, werden erstere als \emph{Literal} bezeichnet.
$$M(F, C) \coloneqq T(F, C \cup X)$$
Für ein Paar $(m, t) \in M \times T$ ist eine Funktion $v_m \colon X \rightarrow T$ ein \emph{Match}, wenn folgendes gilt.
$$\mathrm{normalize}(\mathrm{eval}(\mathrm{id}, \tilde v_m)(m))= t$$
$$\tilde v_m(c) = \begin{cases}
	v_m(c) & c \in X\\
	c         & c \in C \setminus X
\end{cases}$$
Jedes Literal ist damit Fixpunkt von $\mathrm{eval}(\mathrm{id}, \tilde v_m)$, wohingegen Mustervariablen auf Nachkommen von $t$ abgebildet werden. 
Klar ist auch, dass ein Match nur für bereits normalisierte Literale $t$ existieren kann, im folgenden werden zudem auch Muster als normalisiert angenommen.\\
Wichtig ist in dem Zusammenhang der Unterschied zwischen der \emph{Musterinterpretation} $(\mathrm{id}, \tilde v_m)$, welche Musterterme als Literale interpretiert und einer Interpretation $(\hat{u}, \hat{v})$ der Literale selbst. Diese zweite Interpretation wird im folgenden als gegeben angenommen. Erneut bezieht sich Kommutativität und Assoziativität von Funktionssymbolen dann auf diese meist implizite Interpretation $(\hat u, \hat v)$.\\

\textbf{Beispiel}\\
Für das Muster $m = +(2, \mathbf a, \mathbf b)$ und das Literal $t = +(2, \sin(x), \cdot(x, y, z))$ ist die Funktion $v_m$ ein Match, wenn $v_m(\mathbf a) = \sin(x)$ und $v_m(\mathbf b) = \cdot(x, y, z)$. Ebenso gültig wäre aber $v_m(\mathbf b) = \sin(x)$ und $v_m(\mathbf a) = \cdot(x, y, z)$, da die Auswertung des Musters $m$ mit der Musterinterpretation noch normalisiert wird, bevor das Ergebnis identisch zu $t$ sein muss.\\

Ein \emph{Matchalgorithmus} ist eine Funktion, die zu einem Paar $(m, t) \in M \times T$ ein Match oder eine Menge von Matches sucht. Mit $\mathcal{P}(A)$ als Potenzmenge der Menge $A$ kann ein Matchalgorithmus damit eine der zwei Formen annehmen.
$$\mathrm{findMatches} \colon M \times T \rightarrow \mathcal{P}(X \rightarrow T)$$
$$\mathrm{findMatch} \colon M \times T \rightarrow X \rightarrow T$$
Es wird sich herausstellen, das die $\mathrm{findMatches}$ genannte Variante elegantere Beschreibungen erlaubt, wohingegen $\mathrm{findMatch}$ in der Laufzeit besser kontrollierbar ist.

\subsection{Erster Matchalgorithmus}

\begin{algorithm}
\caption{$\mathrm{findMatchingPermutation} \colon M \times T \rightarrow \mathcal{P}(X \rightarrow T)$}\label{findMatchingPermutation}
\begin{algorithmic}[1] %[1] -> jede zeile nummeriert
\Require $m \in M$, $t \in T$
\If {$m \in X$}
	\State \textbf{return} $\{v \in (X \rightarrow T) ~|~ v(m) = t\}$ 
\EndIf
\If {$m = f(m_1, \dots, m_n)$ und $t = f(t_1, \dots, t_n)$}
	\If {$f$ kommutativ}
		\State $V \leftarrow \emptyset$
		\ForAll {$(\tilde t_1, \dots, \tilde t_n)$ permutation von $(t_1, \dots, t_n)$}
			\State $V \leftarrow V \cup \bigcap_{i = 1}^n {\mathrm{findMatchingPermutation}(m_i, \tilde t_i)}$
		\EndFor
		\State \textbf{return} $V$
	\Else
		\State \textbf{return} $\bigcap_{i = 1}^n {\mathrm{findMatchingPermutation}(m_i, t_i)}$
	\EndIf
\EndIf
\State \textbf{return} $\emptyset$
\end{algorithmic}
\end{algorithm}

Der erste Matchalgorithmus, dargestellt als Argorithmus \ref{findMatchingPermutation}, findet bereits eine große Teilmenge aller möglichen Matches. Es gibt allerdings zwei schwerwiegende Probleme. Erstens erzeugt Zeile 7 für eine Funktionsanwendung mit $n$ Parametern alle $n!$ Permutationen dieser Parameter, wobei ein Muster sogar mehrere solche Funktionsanwendungen auch mit gegenseitiger Abstammung enthalten kann. Sollte es ein Match geben, ist die Laufzeit damit in $\Omega(n!)$, wobei  $\Omega$ das Landau-Symbol ist, welches die tatsächliche Laufzeit asymptotisch nach unten abschätzt.

Das zweite Problem  ist folgendes: Assoziative Funktionsanwendungen wurden vor der Matchsuche bereits von $\mathrm{combine}$ (Algorithmus \ref{combine}) miteinander verschmolzen, so dass ein Muster mindestens mit der äußersten Funktionsanwendung nicht nur die Terme matchen will, die in ihrer äußersten Funktionsanwendung exakt gleich viele Parameter wie das Muster haben, sondern auch die Funktionsanwendungen mit mehr Parametern (immer vorausgesetzt die einzelnen Parameter des Musters sind matchbar). Für die Lösung dieses zweiten Problems gibt es mehrere Optionen.
Möglich ist, im Matchalgorithmus nicht nur darauf zu achten, ob ein Funktionssymbol kommutativ ist, sondern auch auf Assoziativität entsprechend zu reagieren, also bei der Matchsuche in einer größeren Funktionsanwendung eines assoziativen Funktionssymbols im Literal testweise immer so viele Parameter zu einzelnen Funktionsanwendungen zusammenzufassen, dass die Parameteranzahl von Muster und Literal in der äußersten Funktionsanwendung gleich sind. Ein Muster mit äußerster assoziativer Funktionsanwendung bräuchte dann immer eine Version mit einer weiteren Matchvariable, die beim Matchprozess sonst übrigbleibende Parameter des Literals \glqq aufsagen\grqq{} kann. Das Muster aus Beispiel \textcolor{red}{\textbf{???}} zur Anwendung der ersten binomischen Formel müsste durch eine zweite Version mit einer Mustervariable $\mathbf{c}$ ergänzt werden.
$$+(\string^(\mathbf a, 2), \cdot(2, \mathbf a, \mathbf b), \string^(\mathbf b, 2), \mathbf c) \rightarrow +(\string^(+(\mathbf a, \mathbf b), 2), \mathbf c)$$
Der Vorteil dieser Umsetzung ist die einfachere mathematische Beschreibung, es wurden schließlich keine neuen Konzepte eingeführt, sondern nur der Algorithmus angepasst. Es gibt allerdings auch drei Nachteile. Zum einen muss jede Regel mit äußerer assoziativer Funktionsanwendung auf der linken Seite jetzt mindestens zwei mal vorliegen: Ein mal mit und ein mal ohne extra Variable $\mathbf c$. Für nicht kommutative Funktionen wird die Anzahl sogar noch größer, da auch Parameter nur nicht kommutativ zusammengefasst werden können, also müssen extra Variablen sowohl vor, als auch hinter dem sonstigen Muster ergänzt werden, so dass es dann vier Regeln geben muss, die den selben Sachverhalt beschreiben. 
Ein weiterer Nachteil des Ansatzes besteht darin, dass zwar assoziative Funktionsanwendungen einfach in einem Muster beschrieben werden können, ein Term aber prinzipiell auch nicht assoziative variadische Funktionssymbole enthalten kann. Ein Muster kann also immer nur eine feste Anzahl von Parametern in einer solchen Funktionsanwendung beschreiben, was Muster praktisch nutzlos für die Manipulation solcher Strukturen macht.
Der finale Nagel im Sarg ist die erneut größer gewordene algorithmische Komplexität des Algorithmus. Dem Autor des Musters ist zwar klar, dass die ergänzte Mustervariable nur sonst übrigbleibende Parameter aufsammeln soll, diese Intention geht aber verloren, wenn $\mathbf c$ auch nur eine normale Mustervariable ist. Vor allem die Möglichkeit einer Mustervariable öfter als ein mal vorzukommen wird für die gerade ergänzten Mustervariablen nicht benötigt, da sie sich gerade dadurch auszeichnen, dass die Teile eines Literals, die mit einer solchen Variable gematcht sind für das eigentliche Muster uninteressant sind.
\textcolor{red}{\textit{Frage: Soll der soeben skizzierte erweiterte Algorithmus auch in Pseudocode beschrieben werden?}}

\subsection{Multi-Mustervariablen}
Die in dieser Arbeit gewählte Lösung zur Beschreibung von beliebig vielen Parametern in einem Muster ist im Prinzip schon mit den ersten Definitionen eingeführt worden. Die Schreibweise $f(ts...)$ als kompakte Alternative zu $f(t_1, \dots, t_n)$ hat genau die Eigenschaften, die wir uns nach Analyse von Algorithmus \ref{findMatchingPermutation} gewünscht haben. Eine \textit{Multi-Mustervariable} der Form $\mathbf{ts...}$ kann also nicht nur genau einen Parameter in einer Funktionsanwendung matchen, sondern beliebig viele, auch null. Dafür darf jede Multi-Mustervariable auf der linken Seite einer Ersetzungsregel nur höchstens ein Mal vorkommen. Die rigorose Beschreibung des Konzeptes gestaltet sich allerdings mit der bisher eingeführten Ideen schwierig, da eine Multi-Mustervariable nur Teil einer Funktionsanwendung ist und damit auch alleine keinen vollständigen Term repräsentiert. Konnte eine Matchfunktion $v \colon X \rightarrow T$ vorher einfach auf die Menge aller Terme abbilden, wäre dies nach hinzufügen der Multi-Mustervariablen nicht mehr möglich. Entsprechend umständlicher würde auch die Beschreibung der Auswertung eines Musters werden. \\

Formal wird die Multi-Mustervariable damit nicht als echtes neues Symbol in die Menge der Muster aufgenommen, sondern ist lediglich eine vereinfachende Schreibweise, die wie auch vorher immer für eine beliebige Anzahl an Teiltermen steht, in diesem Fall Mustervariablen. Ein Muster mit einer Multi-Mustervariable $\mathbf{ts...}$ repräsentiert also formal unendlich viele konkrete Muster mit konkreten Mustervariablen $\mathbf{t_i}$:
\begin{equation*}
    \begin{split}
    		f(\mathbf{ts...}) = \{&f(), \\
    		&f(\mathbf{t_1}),\\
    		&f(\mathbf{t_1}, \mathbf{t_2}), \\
    		&f(\mathbf{t_1}, \mathbf{t_2}, \mathbf{t_3}), \\
    		&\dots \}    		
    \end{split}
\end{equation*}
Für die folgenden Algorithmen und auch in der echten Umsetzung ist es allerdings nicht praktikabel diese Definition anzuwenden, Multi-Mustervariablen werden also formal inkorrekt als einzelne Symbole in einem tatsächlichen Muster betrachtet.

Die Anwendung der ersten binomischen Formel kann jetzt in einer einzigen Regel beschrieben werden.
$$+(\string^(\mathbf a, 2), \cdot(2, \mathbf a, \mathbf b), \string^(\mathbf b, 2), \mathbf{cs...}) \rightarrow +(\string^(+(\mathbf a, \mathbf b), 2), \mathbf{cs...})$$

\section{Termersetzungssystem}
\textcolor{red} {
\begin{itshape}
Anmerkung: Dieses Kapitel wird recht kurz und ist auch als Unterkapitel von Patternmatching denkbar. 
Während in Patternmatching (bisher) immer nur mit einem Muster und dem Gesamtterm gematcht wird, Werden hier mehrere Muster auf jeden Teilterm angewendet, bis keine Anwendung mehr möglich ist
\end{itshape}
}

\section{Umsetzung in C\texttt{++}} \label {secUmsetzungInCpp}

\textcolor{red} {
\begin{itshape}
Anmerkung: Hier wird erläutert, wie meine konkrete Implementierung Terme speichert und verwaltet und wie die Algorithmen konkret umgesetzt sind. Vielleicht auch noch wo anders im Text anzufinden, aber auch jeden Fall auch hier ist meine Implementierung der Lambdafunktion als Term, was die Vereinfachungsmuster noch etwas ausdrucksstärker macht. Dann gibt es noch spezielle Matchvariablen, die darauf optimiert sind bestimmte Werte zu matchen, die werde ich an dieser Stelle auch erläutern, mathematisch rigoros ist mir das glaube ich zu aufwendig.
Mögliche Tangenten:
\begin{itemize}
\item {Ausflug in die Codegenerierung mit Templates für Funktionen, die genau ein Muster matchen (ist ein recht tiefes Kaninchenloch)}
\item {Meine Idee (und Umsetzung) einer Art Aufzählung (in cpp und Co. als enum in der Sprache enthalten), die Hierarchien erlaubt und damit Basis eines (wie ich finde) relativ eleganten Typsystems für die einzelnen Arten von Termknoten darstellt}
\item {Idee und Umsetzung eines sehr einfachen Typsystems}
\item{Möglichkeit Mustervariablen nur zu matchen, sollten Extrabedingungen erfüllt sein}
\item {Speichermanagement}
\end{itemize}
\end{itshape}
}

Die C\texttt{++} Implementierung ist nicht nur nicht generisch in ihren Mengen $F$ und $C$, sondern unterscheidt zudem auf der Typebene nicht zwischen den beiden. Konkret ist ein Literal ein Baum, welcher als innere Knoten Funktionsanwendungen und Lambdafunktionen und als äußere Knoten Komplexe Zahlen, durch Strings identifizierte Symbole und Platzhalter für Lambda Parameter enthalten kann. 

Die Einzelnen Knoten haben dabei folgende Eigenschaften:
\begin{itemize}
\item \mintinline{cpp}{Literal::symbol} stellt ein beliebiges, dem System möglicherweise unbekanntes Symbol da. Für den Nutzer ist ein Symbol durch einen String identifiziert, welcher lateinische Großbuchstaben und Kleinbuchstaben, Dezimalziffern und Unterstriche enthalten kann, wobei das erste Zeichen keine Ziffer sein darf. Intern sind die tatsächlichen Zeichenketten nur in einer zentralen Tabelle zu finden, im einzelnen Term ist ein String durch seinen Index in dieser Tabelle beschrieben. Nachteil dieser Vorgehensweise ist, dass ohne viel organisatorischen Mehraufwand nie in der Programmlaufzeit ein Eintrag in der zentralen Namenstabelle gelöscht werden darf, da nicht klar ist, ob es noch Symbole mit diesem Namen gibt. Das ist in der Praxis allerdings kein Problem, da Symbolnamen nicht mutierbar sind, also jedes tatsächlich genutzte Symbol auch nur genau einen Eintrag produziert.
\item \mintinline{cpp}{Literal::complex} repräsentiert eine Instanz von \mintinline{cpp}{std::complex<double>}, also ein Paar aus zwei 64-bit Fließkommazahlen, welche eine Komplexe Zahl in karthesischen Koordinaten annähren. Für ein Computeralgebrasystem ist die Nutzung von Fließkommazahlen problematisch, da (sofern nicht anders gewünscht) nur exakte Transformationen durchgeführt werden sollen. Der haupsächliche Grund in der Nutzung liegt darin, dass grundlegende Operationen und einige Funktionen wie Sinus und Cosinus bereits in der Standardbibliothek definiert sind. 
\item \mintinline{cpp}{Literal::lambda} repräsentiert eine anonyme Funktion, also eine Funktion, die nur über ihre Abbildungsvorschrift definiert ist. Als Parameteranzahl erlaubt ist dabei eine natürliche Zahl $n \in [1, 2^{16} - 1]$. Speichern tut ein Lambda damit primär seine Parameteranzahl und einen Verweis auf den Term, der die Abbildungsvorschrift darstellt.
\item \mintinline{cpp}{Literal::lambda_param} ist der Platzhalter, der in der Definition der Abbildungsvorschrift eines Lambdas für einen bestimmten Parameter steht. Identifiziert wird der einzelne Parameter dabei durch einen Index.
\item \mintinline{cpp}{Literal::f_app} Entspricht der Funktionsanwendung aus vorrangegangenden Abschnitten, ist also ein Tupel aus Verweisen auf weitere Knoten, wobei der erste Verweis als anzuwendene Funktion interpretiert wird, alle weiteren Verweise als Parameter.
\end{itemize}

\begin{listing}
\small
\begin{minted}[linenos=true]{cpp}
enum class Literal
{
    symbol,
    complex,
    lambda,
    lambda_param,
    f_app,
};
\end{minted}
\label{abbLiteralEnum}
\caption{Mögliche Knotentypen in einem Literal}
\end{listing}

Die Knoten eines Termbaumes sind in einem Array gespeichert, wobei dem einzelnen Arrayelement nicht zu entnehmen ist, welche Art Knoten es repräsentiert. Ein Verweis auf einen Knoten beinhaltet also nicht nur den Arrayindex, sondern auch den Knotentyp. Als Paar zusammengefasst sind beide in der Klasse \mintinline{cpp}{NodeIndex}. 
Da die Knotentypen \mintinline{cpp}{Literal::symbol} und \mintinline{cpp}{Literal::lambda_param} durch einen vorzeichenlosen Integer bereits eindeutig dargestellt werden können, hat der Index einer \mintinline{cpp}{NodeIndex} Instanz für diese Typen nicht die Bedeutung eines Arrayindex, sondern ist direkt die komplette Beschreibung des Knoteninhaltes.

\subsection{Lambdafunktionen} \label{subsecLambdafunktionen}


\section{Vereinfachen von arithmetischen Termen}
\begin{itshape}
\textcolor{red} {Anmerkung zur Anmerkung: ab hier sind es nur noch Anmerkungen, da wird Farbe gespart (in echt mag \LaTeX{}  es nicht über Kapitelgrenzen hinweg zu färben).}
Anmerkung: Ich habe begonnen das Termersetzungssystem zu entwickeln, um Arithmetische Ausdrücke zu vereinfachen (etwa $a + 2 a \rightarrow 3 a$). Wie genau ich das umsetze, wird in diesem Abschnitt erläutert.
\\Während die Datenstruktur und der Matchingalgorithmus schon benutzbar sind, ist dieser Teil von mir bisher so gut wie gar nicht implementiert worden. Der grobe Plan ist aber folgender:
\begin{enumerate}
    \item Funktionen höherer Ordnung anwenden:
    \begin{itemize}
        \item ableiten (Prototyp dafür steht schon)
        \item vielleicht integrieren (soll für den allgemeinen Fall wohl schwer sein)
        \item vielleicht fouriertransformieren
        \item vielleicht laplacetransformieren
        \item ganz ganz ganz ganz vielleicht Differentialgleichungen lösen
    \end{itemize}
    \item Normalform herstellen:
    \begin{itemize}
        \item alles ausmultiplizieren ($a\cdot (b + c) \rightarrow a\cdot b + a\cdot c$)
        \item Vorzeichen aus ungeraden Funktionen herausziehen ($\sin(-x) \rightarrow -\sin(x)$)
        \item Vorzeichen in geraden Funktionen auf plus setzen ($\cos(-x) \rightarrow \cos(x)$)
        \item Überlegen, wie man das selbe für Fälle mit Summen im Argument definiert ($\cos(a - b)$ vs. $\cos(b - a)$)
        \item bekannte Faktoren aus Potenz ziehen ($(3 x)^2 \rightarrow 9 x^2$)
        \item \dots
    \end{itemize}
    \item Vereinfachen:
    \begin{itemize}
        \item manche Transformationen sollten immer angewendet werden (etwa $\sin^2(x) + \cos^2(x) \rightarrow 1)$
        \item andere Transformationen nur ausprobieren und mit einer passenden Metrik gucken, wie gut ein Term nach Anwendung noch weiter vereinfacht werden kann (etwa, wenn man aus verschiedenen Optionen des Ausklammerns wählen kann)
        \item vielleicht Linearfaktorzerlegung von Polynomen (schätze ich für den allgemeinen Fall schwierig ein, solange ich nur exakte Operationen zulasse)
        \item vielleicht Polynomdivision (schätze ich genau so schwierig ein, zumindest wenn ich nicht vorher schon Linearfaktoren habe)
        \item \dots
    \end{itemize}
\end{enumerate}
~\\~
Anmerkung 1: Die Normalform ist notwendig, um zu garantieren, dass mehrfaches Auftreten eines Teilbaums / Teilterms auch erkannt wird. \\
Anmerkung 2: es kann sein, dass ich manche Eigenschaften der Normalformauch während des Vereinfachungsschrittes immer wieder wiederherstellen muss.

\subsection{Vergleich meiner Features mit anderen Computeralgebrasystemen}
Ich bin ja nicht der erste, der auf die Idee kommt, Terme zusammenzufassen. Wolphram Alpha und Maple sind zwar nicht Open Source, aber andere Optionen, wie etwa SymPy aus der Python Standardbibliothek soweit ich weiß schon. Da lässt sich bestimmt ein bisschen vergleichen, wie andere Leute die selben Probleme lösen.
\end{itshape}

\section{Zusammenfassung}
\begin{itshape}
Was halt in eine Zusammenfassung kommt
\end{itshape}


\printbibliography

\end{document}
